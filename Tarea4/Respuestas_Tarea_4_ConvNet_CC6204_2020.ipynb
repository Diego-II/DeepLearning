{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Respuestas_Tarea_4_ConvNet_CC6204_2020",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zhjpqvcdo5o"
      },
      "source": [
        "# Tarea 4: Redes Convolucionales <br/> CC6204 Deep Learning, Universidad de Chile <br/> Hoja de Respuestas\n",
        "\n",
        "## Nombre: \n",
        "Fecha de entrega: 11 de diciembre de 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64BkmYga3UN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a258e6-83ef-4b05-c2de-6cd461da2d75"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Aqui descargamos algunas funciones utiles para resolver la tarea\n",
        "if not os.path.exists('utils.py'):\n",
        "  !wget https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea4/utils.py\n",
        "\n",
        "from utils import ImageCaptionDataset, train_for_classification, train_for_retrieval\n",
        "\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "!pip install ipdb\n",
        "import ipdb"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/44/8c/76b33b115f4f2c090e2809a0247fe777eb3832f9d606479bf0139b29ca2c/ipdb-0.13.4.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (50.3.2)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.2.5)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.4-cp36-none-any.whl size=10971 sha256=9de33d018b682d5e9b7baa67d5dca2bfc0352e8c24dc6d5572d0600152bdd842\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/51/e4/c91c61e3481a1a967beb18c4ea7a2b138a63cce94170b2e206\n",
            "Successfully built ipdb\n",
            "Installing collected packages: ipdb\n",
            "Successfully installed ipdb-0.13.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtwf7_btPh7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1905269f-2c64-4ef6-8832-1e2982f7ff84"
      },
      "source": [
        "# Aqui instalamos la libreria de correccion del curso\n",
        "!pip install -U \"git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect\"\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# importamos las herramientas del curso\n",
        "from cc6204 import AutoCorrect, FailedTest\n",
        "\n",
        "# En caso que se les indique, cambia el host y port que posteamos en u-cursos\n",
        "corrector = AutoCorrect(host=\"cc6204.dcc.uchile.cl\", port=443)\n",
        "\n",
        "# En caso que se les indique, cambia el token que te daremos en u-cursos\n",
        "token = \"]ye/Ox;nsz\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cc6204\n",
            "  Cloning https://github.com/dccuchile/CC6204.git (to revision master) to /tmp/pip-install-6nx0uka4/cc6204\n",
            "  Running command git clone -q https://github.com/dccuchile/CC6204.git /tmp/pip-install-6nx0uka4/cc6204\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from cc6204) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->cc6204) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->cc6204) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->cc6204) (0.16.0)\n",
            "Building wheels for collected packages: cc6204\n",
            "  Building wheel for cc6204 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cc6204: filename=cc6204-0.5.0-cp36-none-any.whl size=5800 sha256=1fb1110d8f0e2d8fbc0a35c8e76043139f95b2e578b1132c9bd036900c512508\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-spub8qd9/wheels/62/f0/30/aadcb7ce24a2f9c935890518e902d4e23bf97b80f47bb64414\n",
            "Successfully built cc6204\n",
            "Installing collected packages: cc6204\n",
            "Successfully installed cc6204-0.5.0\n",
            "Connection stablished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnux9hNPSVYv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(loss, score1, score1_title='Accuracy', score2=None, score2_title=None):\n",
        "  f1 = plt.figure(1)\n",
        "  ax1 = f1.add_subplot(111)\n",
        "  ax1.set_title(\"Loss\")    \n",
        "  ax1.set_xlabel('epochs')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.plot(loss, c='r')\n",
        "  ax1.legend(['train-loss'])\n",
        "  f1.show()\n",
        "\n",
        "  f2 = plt.figure(2)\n",
        "  ax2 = f2.add_subplot(111)\n",
        "  ax2.set_title(score1_title)    \n",
        "  ax2.set_xlabel('epochs')\n",
        "  ax2.set_ylabel(score1_title.lower())\n",
        "  ax2.plot(score1[0], c='b')\n",
        "  ax2.plot(score1[1], c='g')\n",
        "  ax2.legend([f'train-{score1_title.lower()}', f'val-{score1_title.lower()}'])\n",
        "  f2.show()\n",
        "\n",
        "  if score2:\n",
        "    f3= plt.figure(3)\n",
        "    ax3 = f3.add_subplot(111)\n",
        "    ax3.set_title(score2_title)    \n",
        "    ax3.set_xlabel('epochs')\n",
        "    ax3.set_ylabel(score2_title.lower())\n",
        "    ax3.plot(score2[0], c='b')\n",
        "    ax3.plot(score2[1], c='g')\n",
        "    ax3.legend([f'train-{score2_title.lower()}', f'val-{score2_title.lower()}'])\n",
        "    f3.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mw8PKh-uF7P"
      },
      "source": [
        "# Parte 1: Arquitectura Convolucional GoogLeNet (y otras) para CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9qzrGbKRRxh"
      },
      "source": [
        "## 1a) Inception Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVhRKwtJ55fg"
      },
      "source": [
        "# Como todas las capas convolucionales del paper usan ReLu, se va a hacer una clase general para facilitar esto:\r\n",
        "class Conv2dRelu(nn.Module):\r\n",
        "  def __init__(\r\n",
        "      self, \r\n",
        "      in_channels,\r\n",
        "      out_channels, \r\n",
        "      **kwargs\r\n",
        "  ):\r\n",
        "    super(Conv2dRelu, self).__init__()\r\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv(x)\r\n",
        "    return F.relu(x)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVeNZDV8RlDr"
      },
      "source": [
        "class InceptionModule(nn.Module):\n",
        "  def __init__(self, \n",
        "               in_channels, \n",
        "               ch_3x3_reduce=96, \n",
        "               ch_5x5_reduce=16,\n",
        "               ch_3x3=128,\n",
        "               ch_5x5=32,\n",
        "               ch_pool_proj=32,\n",
        "               ch_1x1=64\n",
        "    ):\n",
        "    super(InceptionModule, self).__init__()\n",
        "    # Acá inicializa todos los parámetros\n",
        "    # Rama 1: Conv2d 1x1 -> Conv2d 3x3\n",
        "    self.branch1 = nn.Sequential(\n",
        "        Conv2dRelu(in_channels, ch_3x3_reduce, kernel_size=1),\n",
        "        Conv2dRelu(ch_3x3_reduce, ch_3x3, kernel_size=3, padding=1)\n",
        "    )\n",
        "    # Rama 2: Conv2dRelu 1x1 -> Conv2dRelu 5x5\n",
        "    self.branch2 = nn.Sequential(\n",
        "        Conv2dRelu(in_channels, ch_5x5_reduce, kernel_size=1),\n",
        "        Conv2dRelu(ch_5x5_reduce, ch_5x5, kernel_size=5, padding=2)\n",
        "    )\n",
        "\n",
        "    # Rama 3: Max_Pool -> Conv2dRelu 1x1\n",
        "    self.branch3 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
        "        Conv2dRelu(in_channels, ch_pool_proj, kernel_size=1)\n",
        "    )\n",
        "\n",
        "    # Rama 4: Conv2dRelu 1x1\n",
        "    self.branch4 = Conv2dRelu(in_channels, ch_1x1, kernel_size=1)\n",
        "        \n",
        "\n",
        "  def _forward(self, x):\n",
        "    # aux para forward:\n",
        "    branch1 = self.branch1(x)\n",
        "    branch2 = self.branch2(x)\n",
        "    branch3 = self.branch3(x)\n",
        "    branch4 = self.branch4(x)\n",
        "\n",
        "    outputs = [branch1, branch2, branch3, branch4]\n",
        "    return outputs\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Calcula la salida como un tensor con cantidad de canales de\n",
        "    # salida dado por ch_3x3 + ch_5x5 + ch_pool_proj + ch_1x1\n",
        "    outputs = self._forward(x)\n",
        "    return torch.cat(outputs, 1)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-net4tfvdce"
      },
      "source": [
        "Esta celda se utiliza para chequear que los tamanos del output sean los correctos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sstah0kkjiUY",
        "outputId": "49baac84-3dd0-44b8-ff44-e678e3c0156c"
      },
      "source": [
        "# Obtengamos algunos parametros para probar tu implementación\r\n",
        "x, in_chs, ch_1x1, ch_3x3_red, ch_3x3, ch_5x5_red, ch_5x5, ch_pool_proj = corrector.get_test_data(homework=4, question=\"1a\", test=1, token=token)\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "  model = InceptionModule(in_chs, ch_1x1, ch_3x3_red, ch_3x3, ch_5x5_red, ch_5x5, ch_pool_proj)\r\n",
        "  s = timer()\r\n",
        "  result = model._forward(torch.tensor(x))\r\n",
        "  for r in result:\r\n",
        "    print(r.shape)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cached test data\n",
            "torch.Size([5, 128, 28, 28])\n",
            "torch.Size([5, 16, 28, 28])\n",
            "torch.Size([5, 32, 28, 28])\n",
            "torch.Size([5, 32, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5AxECptzqin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f1fb2f-5f78-46b3-8ac6-0f60a904d4bc"
      },
      "source": [
        "# Tests del API del curso para el InceptionModule\n",
        "\n",
        "# Obtengamos algunos parametros para probar tu implementación\n",
        "x, in_chs, ch_1x1, ch_3x3_red, ch_3x3, ch_5x5_red, ch_5x5, ch_pool_proj = corrector.get_test_data(homework=4, question=\"1a\", test=1, token=token)\n",
        "\n",
        "# Corramos tu implementación de InseptionModule para ver como se comporta\n",
        "with torch.no_grad():\n",
        "  model = InceptionModule(in_chs, ch_3x3_red, ch_5x5_red, ch_3x3, ch_5x5, ch_pool_proj, ch_1x1)\n",
        "  s = timer()\n",
        "  result = model(torch.tensor(x))\n",
        "  t = timer()-s\n",
        "\n",
        "# Veamos si todo fue OK :)\n",
        "corrector.submit(homework=4, question=\"1a\", test=1, token=token, answer=list(result.size()), time=t)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cached test data\n",
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJG69heDRag8"
      },
      "source": [
        "## 1b) GoogLeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz6dtn7BMMPS"
      },
      "source": [
        "# Modulo auxiliar de prediccion intermedia:\r\n",
        "class InceptionAux(nn.Module):\r\n",
        "  def __init__(\r\n",
        "      self, \r\n",
        "      in_channels, \r\n",
        "      num_classes\r\n",
        "  ):\r\n",
        "    super(InceptionAux,self).__init__()\r\n",
        "    #self.avgpool = nn.AvgPool2d(kernel_size= 5,stride=3)\r\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "\r\n",
        "    self.conv = Conv2dRelu(in_channels, 128, kernel_size=1)\r\n",
        "\r\n",
        "    self.fc1 = nn.Linear(128,1024)\r\n",
        "    self.fc2 = nn.Linear(1024, num_classes)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.avgpool(x)\r\n",
        "    x = self.conv(x)\r\n",
        "    x = torch.flatten(x,1)\r\n",
        "    x = self.fc1(x)\r\n",
        "    x = F.relu(x, inplace=True)\r\n",
        "    x = F.dropout(x, 0.7, training=self.training)\r\n",
        "    x = self.fc2(x)\r\n",
        "\r\n",
        "    return x\r\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd3iSAd7oXKN"
      },
      "source": [
        "# basado en la documentacion de Pytorch/Vision/GoogLeNet. \n",
        "class GoogLeNet(nn.Module):\n",
        "  def __init__(self, n_classes, use_aux_logits=True):\n",
        "    super(GoogLeNet, self).__init__()\n",
        "    self.use_aux_logits = use_aux_logits\n",
        "    # Define las capas de convolución y pooling de GoogLeNet\n",
        "    # Conv 1\n",
        "    self.conv1 = Conv2dRelu(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "    # Max Pool 1\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "    \n",
        "    # Conv 2\n",
        "    self.conv2 = Conv2dRelu(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1)\n",
        "    # Max Pool 2\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "    # in_channels, ch_3x3_reduce=96, ch_5x5_reduce=16,\n",
        "    # ch_3x3=128, ch_5x5=32, ch_pool_proj=32, ch_1x1=64\n",
        "\n",
        "    # Inception 3a\n",
        "    self.inception3a = InceptionModule(in_channels=192, ch_3x3_reduce=96, ch_5x5_reduce=16, ch_3x3=128, ch_5x5=32, ch_pool_proj=32, ch_1x1=64)\n",
        "    # Inception 3b\n",
        "    self.inception3b = InceptionModule(in_channels=256, ch_3x3_reduce=128, ch_5x5_reduce=32, ch_3x3=192, ch_5x5=96, ch_pool_proj=64, ch_1x1=128)\n",
        "\n",
        "    # Max Pool 3\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "    # Inception 4a\n",
        "    self.inception4a = InceptionModule(in_channels=480, ch_3x3_reduce=96, ch_5x5_reduce=16, ch_3x3=208, ch_5x5=48, ch_pool_proj=64, ch_1x1=192)\n",
        "    # Inception 4b\n",
        "    self.inception4b = InceptionModule(in_channels=512, ch_3x3_reduce=112, ch_5x5_reduce=24, ch_3x3=224, ch_5x5=64, ch_pool_proj=64, ch_1x1=160)\n",
        "    # Inception 4c\n",
        "    self.inception4c = InceptionModule(in_channels=512, ch_3x3_reduce=128, ch_5x5_reduce=24, ch_3x3=256, ch_5x5=64, ch_pool_proj=64, ch_1x1=128)\n",
        "    # Inception 4d\n",
        "    self.inception4d = InceptionModule(in_channels=512, ch_3x3_reduce=144, ch_5x5_reduce=32, ch_3x3=288, ch_5x5=64, ch_pool_proj=64, ch_1x1=112)\n",
        "    # Inception 4e\n",
        "    self.inception4e = InceptionModule(in_channels=528, ch_3x3_reduce=160, ch_5x5_reduce=32, ch_3x3=320, ch_5x5=128, ch_pool_proj=128, ch_1x1=256)\n",
        "\n",
        "    # Max Pool 4\n",
        "    self.maxpool4  = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "    # Inception 5a\n",
        "    self.inception5a = InceptionModule(in_channels=832, ch_3x3_reduce=160, ch_5x5_reduce=32, ch_3x3=320, ch_5x5=128, ch_pool_proj=128, ch_1x1=256)\n",
        "    # Inception 5b\n",
        "    self.inception5b = InceptionModule(in_channels=832, ch_3x3_reduce=192, ch_5x5_reduce=48, ch_3x3=384, ch_5x5=128, ch_pool_proj=128, ch_1x1=384)\n",
        "\n",
        "    # Avg Pool\n",
        "    #self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    # Dropout .4\n",
        "    self.dropout = nn.Dropout2d(0.4)\n",
        "\n",
        "    # Linear\n",
        "    # Capa de salida (antes de la función de salida)\n",
        "    self.fc_out = nn.Linear(1024, n_classes)\n",
        "\n",
        "    # Decide si usar la clasificación auxiliar\n",
        "    if self.use_aux_logits:\n",
        "      self.aux1 = InceptionAux(512, n_classes)\n",
        "      self.aux2 = InceptionAux(528, n_classes)\n",
        "    else:\n",
        "      self.aux1 = None  # type: ignore[assignment]\n",
        "      self.aux2 = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.use_aux_logits and self.training:\n",
        "      aux_logits = []\n",
        "    else:\n",
        "      aux_logits = None\n",
        "    x = self.conv1(x)\n",
        "    \n",
        "    x = self.maxpool1(x)\n",
        "    \n",
        "    x = self.conv2(x)\n",
        "    \n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "\n",
        "    x = self.inception3a(x)\n",
        "  \n",
        "    x = self.inception3b(x)\n",
        "\n",
        "    x = self.maxpool3(x)\n",
        "    \n",
        "    x = self.inception4a(x)\n",
        "\n",
        "    # Crea una lista para los logits auxiliares si fuera necesario\n",
        "    if self.use_aux_logits:\n",
        "      if self.training:\n",
        "        aux1_out = self.aux1(x)\n",
        "        aux_logits.append(aux1_out)\n",
        "    else:\n",
        "      aux1_out = None\n",
        "    \n",
        "\n",
        "    x = self.inception4b(x)\n",
        "    \n",
        "    x = self.inception4c(x)\n",
        "    \n",
        "    x = self.inception4d(x)\n",
        "\n",
        "    # Si se usa la clasificación auxiliar, computa logits auxiliares\n",
        "    if self.use_aux_logits:\n",
        "      if self.training:\n",
        "        aux2_out = self.aux2(x)\n",
        "        aux_logits.append(aux2_out)\n",
        "    else:\n",
        "      aux2_out = None\n",
        "\n",
        "    # Continúa computando las representaciones internas de la red\n",
        "    x = self.inception4e(x)\n",
        "    \n",
        "    x = self.maxpool4(x)\n",
        "\n",
        "\n",
        "    x = self.inception5a(x)\n",
        "    hidden = x.detach().clone()\n",
        "    x = self.inception5b(x)\n",
        "    \n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    \n",
        "    x = torch.flatten(x, 1)\n",
        "    \n",
        "    x = self.dropout(x)\n",
        "    x = self.fc_out(x)\n",
        "    \n",
        "    #return x, aux2_out, aux1_out\n",
        "\n",
        "    # En hidden debes devolver alguna de las capas oculta de la red\n",
        "    return {'hidden': hidden, 'logits': x, 'aux_logits': aux_logits}"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWs77G8OXURU",
        "outputId": "830a8b91-a23b-4e0b-c83d-2c032ff388ba"
      },
      "source": [
        "device = 'cuda'\r\n",
        "test_model = GoogLeNet(n_classes=1000, use_aux_logits=True).to(device)\r\n",
        "summary(test_model, input_size=(3, 32, 32))"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "        Conv2dRelu-2           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-3             [-1, 64, 8, 8]               0\n",
            "            Conv2d-4            [-1, 192, 8, 8]         110,592\n",
            "        Conv2dRelu-5            [-1, 192, 8, 8]               0\n",
            "         MaxPool2d-6            [-1, 192, 4, 4]               0\n",
            "            Conv2d-7             [-1, 96, 4, 4]          18,432\n",
            "        Conv2dRelu-8             [-1, 96, 4, 4]               0\n",
            "            Conv2d-9            [-1, 128, 4, 4]         110,592\n",
            "       Conv2dRelu-10            [-1, 128, 4, 4]               0\n",
            "           Conv2d-11             [-1, 16, 4, 4]           3,072\n",
            "       Conv2dRelu-12             [-1, 16, 4, 4]               0\n",
            "           Conv2d-13             [-1, 32, 4, 4]          12,800\n",
            "       Conv2dRelu-14             [-1, 32, 4, 4]               0\n",
            "        MaxPool2d-15            [-1, 192, 4, 4]               0\n",
            "           Conv2d-16             [-1, 32, 4, 4]           6,144\n",
            "       Conv2dRelu-17             [-1, 32, 4, 4]               0\n",
            "           Conv2d-18             [-1, 64, 4, 4]          12,288\n",
            "       Conv2dRelu-19             [-1, 64, 4, 4]               0\n",
            "  InceptionModule-20            [-1, 256, 4, 4]               0\n",
            "           Conv2d-21            [-1, 128, 4, 4]          32,768\n",
            "       Conv2dRelu-22            [-1, 128, 4, 4]               0\n",
            "           Conv2d-23            [-1, 192, 4, 4]         221,184\n",
            "       Conv2dRelu-24            [-1, 192, 4, 4]               0\n",
            "           Conv2d-25             [-1, 32, 4, 4]           8,192\n",
            "       Conv2dRelu-26             [-1, 32, 4, 4]               0\n",
            "           Conv2d-27             [-1, 96, 4, 4]          76,800\n",
            "       Conv2dRelu-28             [-1, 96, 4, 4]               0\n",
            "        MaxPool2d-29            [-1, 256, 4, 4]               0\n",
            "           Conv2d-30             [-1, 64, 4, 4]          16,384\n",
            "       Conv2dRelu-31             [-1, 64, 4, 4]               0\n",
            "           Conv2d-32            [-1, 128, 4, 4]          32,768\n",
            "       Conv2dRelu-33            [-1, 128, 4, 4]               0\n",
            "  InceptionModule-34            [-1, 480, 4, 4]               0\n",
            "        MaxPool2d-35            [-1, 480, 2, 2]               0\n",
            "           Conv2d-36             [-1, 96, 2, 2]          46,080\n",
            "       Conv2dRelu-37             [-1, 96, 2, 2]               0\n",
            "           Conv2d-38            [-1, 208, 2, 2]         179,712\n",
            "       Conv2dRelu-39            [-1, 208, 2, 2]               0\n",
            "           Conv2d-40             [-1, 16, 2, 2]           7,680\n",
            "       Conv2dRelu-41             [-1, 16, 2, 2]               0\n",
            "           Conv2d-42             [-1, 48, 2, 2]          19,200\n",
            "       Conv2dRelu-43             [-1, 48, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 480, 2, 2]               0\n",
            "           Conv2d-45             [-1, 64, 2, 2]          30,720\n",
            "       Conv2dRelu-46             [-1, 64, 2, 2]               0\n",
            "           Conv2d-47            [-1, 192, 2, 2]          92,160\n",
            "       Conv2dRelu-48            [-1, 192, 2, 2]               0\n",
            "  InceptionModule-49            [-1, 512, 2, 2]               0\n",
            "AdaptiveAvgPool2d-50            [-1, 512, 1, 1]               0\n",
            "           Conv2d-51            [-1, 128, 1, 1]          65,536\n",
            "       Conv2dRelu-52            [-1, 128, 1, 1]               0\n",
            "           Linear-53                 [-1, 1024]         132,096\n",
            "           Linear-54                 [-1, 1000]       1,025,000\n",
            "     InceptionAux-55                 [-1, 1000]               0\n",
            "           Conv2d-56            [-1, 112, 2, 2]          57,344\n",
            "       Conv2dRelu-57            [-1, 112, 2, 2]               0\n",
            "           Conv2d-58            [-1, 224, 2, 2]         225,792\n",
            "       Conv2dRelu-59            [-1, 224, 2, 2]               0\n",
            "           Conv2d-60             [-1, 24, 2, 2]          12,288\n",
            "       Conv2dRelu-61             [-1, 24, 2, 2]               0\n",
            "           Conv2d-62             [-1, 64, 2, 2]          38,400\n",
            "       Conv2dRelu-63             [-1, 64, 2, 2]               0\n",
            "        MaxPool2d-64            [-1, 512, 2, 2]               0\n",
            "           Conv2d-65             [-1, 64, 2, 2]          32,768\n",
            "       Conv2dRelu-66             [-1, 64, 2, 2]               0\n",
            "           Conv2d-67            [-1, 160, 2, 2]          81,920\n",
            "       Conv2dRelu-68            [-1, 160, 2, 2]               0\n",
            "  InceptionModule-69            [-1, 512, 2, 2]               0\n",
            "           Conv2d-70            [-1, 128, 2, 2]          65,536\n",
            "       Conv2dRelu-71            [-1, 128, 2, 2]               0\n",
            "           Conv2d-72            [-1, 256, 2, 2]         294,912\n",
            "       Conv2dRelu-73            [-1, 256, 2, 2]               0\n",
            "           Conv2d-74             [-1, 24, 2, 2]          12,288\n",
            "       Conv2dRelu-75             [-1, 24, 2, 2]               0\n",
            "           Conv2d-76             [-1, 64, 2, 2]          38,400\n",
            "       Conv2dRelu-77             [-1, 64, 2, 2]               0\n",
            "        MaxPool2d-78            [-1, 512, 2, 2]               0\n",
            "           Conv2d-79             [-1, 64, 2, 2]          32,768\n",
            "       Conv2dRelu-80             [-1, 64, 2, 2]               0\n",
            "           Conv2d-81            [-1, 128, 2, 2]          65,536\n",
            "       Conv2dRelu-82            [-1, 128, 2, 2]               0\n",
            "  InceptionModule-83            [-1, 512, 2, 2]               0\n",
            "           Conv2d-84            [-1, 144, 2, 2]          73,728\n",
            "       Conv2dRelu-85            [-1, 144, 2, 2]               0\n",
            "           Conv2d-86            [-1, 288, 2, 2]         373,248\n",
            "       Conv2dRelu-87            [-1, 288, 2, 2]               0\n",
            "           Conv2d-88             [-1, 32, 2, 2]          16,384\n",
            "       Conv2dRelu-89             [-1, 32, 2, 2]               0\n",
            "           Conv2d-90             [-1, 64, 2, 2]          51,200\n",
            "       Conv2dRelu-91             [-1, 64, 2, 2]               0\n",
            "        MaxPool2d-92            [-1, 512, 2, 2]               0\n",
            "           Conv2d-93             [-1, 64, 2, 2]          32,768\n",
            "       Conv2dRelu-94             [-1, 64, 2, 2]               0\n",
            "           Conv2d-95            [-1, 112, 2, 2]          57,344\n",
            "       Conv2dRelu-96            [-1, 112, 2, 2]               0\n",
            "  InceptionModule-97            [-1, 528, 2, 2]               0\n",
            "AdaptiveAvgPool2d-98            [-1, 528, 1, 1]               0\n",
            "           Conv2d-99            [-1, 128, 1, 1]          67,584\n",
            "      Conv2dRelu-100            [-1, 128, 1, 1]               0\n",
            "          Linear-101                 [-1, 1024]         132,096\n",
            "          Linear-102                 [-1, 1000]       1,025,000\n",
            "    InceptionAux-103                 [-1, 1000]               0\n",
            "          Conv2d-104            [-1, 160, 2, 2]          84,480\n",
            "      Conv2dRelu-105            [-1, 160, 2, 2]               0\n",
            "          Conv2d-106            [-1, 320, 2, 2]         460,800\n",
            "      Conv2dRelu-107            [-1, 320, 2, 2]               0\n",
            "          Conv2d-108             [-1, 32, 2, 2]          16,896\n",
            "      Conv2dRelu-109             [-1, 32, 2, 2]               0\n",
            "          Conv2d-110            [-1, 128, 2, 2]         102,400\n",
            "      Conv2dRelu-111            [-1, 128, 2, 2]               0\n",
            "       MaxPool2d-112            [-1, 528, 2, 2]               0\n",
            "          Conv2d-113            [-1, 128, 2, 2]          67,584\n",
            "      Conv2dRelu-114            [-1, 128, 2, 2]               0\n",
            "          Conv2d-115            [-1, 256, 2, 2]         135,168\n",
            "      Conv2dRelu-116            [-1, 256, 2, 2]               0\n",
            " InceptionModule-117            [-1, 832, 2, 2]               0\n",
            "       MaxPool2d-118            [-1, 832, 1, 1]               0\n",
            "          Conv2d-119            [-1, 160, 1, 1]         133,120\n",
            "      Conv2dRelu-120            [-1, 160, 1, 1]               0\n",
            "          Conv2d-121            [-1, 320, 1, 1]         460,800\n",
            "      Conv2dRelu-122            [-1, 320, 1, 1]               0\n",
            "          Conv2d-123             [-1, 32, 1, 1]          26,624\n",
            "      Conv2dRelu-124             [-1, 32, 1, 1]               0\n",
            "          Conv2d-125            [-1, 128, 1, 1]         102,400\n",
            "      Conv2dRelu-126            [-1, 128, 1, 1]               0\n",
            "       MaxPool2d-127            [-1, 832, 1, 1]               0\n",
            "          Conv2d-128            [-1, 128, 1, 1]         106,496\n",
            "      Conv2dRelu-129            [-1, 128, 1, 1]               0\n",
            "          Conv2d-130            [-1, 256, 1, 1]         212,992\n",
            "      Conv2dRelu-131            [-1, 256, 1, 1]               0\n",
            " InceptionModule-132            [-1, 832, 1, 1]               0\n",
            "          Conv2d-133            [-1, 192, 1, 1]         159,744\n",
            "      Conv2dRelu-134            [-1, 192, 1, 1]               0\n",
            "          Conv2d-135            [-1, 384, 1, 1]         663,552\n",
            "      Conv2dRelu-136            [-1, 384, 1, 1]               0\n",
            "          Conv2d-137             [-1, 48, 1, 1]          39,936\n",
            "      Conv2dRelu-138             [-1, 48, 1, 1]               0\n",
            "          Conv2d-139            [-1, 128, 1, 1]         153,600\n",
            "      Conv2dRelu-140            [-1, 128, 1, 1]               0\n",
            "       MaxPool2d-141            [-1, 832, 1, 1]               0\n",
            "          Conv2d-142            [-1, 128, 1, 1]         106,496\n",
            "      Conv2dRelu-143            [-1, 128, 1, 1]               0\n",
            "          Conv2d-144            [-1, 384, 1, 1]         319,488\n",
            "      Conv2dRelu-145            [-1, 384, 1, 1]               0\n",
            " InceptionModule-146           [-1, 1024, 1, 1]               0\n",
            "AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0\n",
            "       Dropout2d-148                 [-1, 1024]               0\n",
            "          Linear-149                 [-1, 1000]       1,025,000\n",
            "================================================================\n",
            "Total params: 9,434,488\n",
            "Trainable params: 9,434,488\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.44\n",
            "Params size (MB): 35.99\n",
            "Estimated Total Size (MB): 37.44\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQs327QW0Fnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77cc442-78c2-4611-c47c-a26ed2f797af"
      },
      "source": [
        "# Tests del API del curso para el InceptionModule\n",
        "\n",
        "# Obtengamos algunos parametros para probar tu implementación\n",
        "x, n_classes, use_aux_logits = corrector.get_test_data(homework=4, question=\"1b\", test=1, token=token)\n",
        "\n",
        "# Corramos tu implementación de InseptionModule para ver como se comporta\n",
        "with torch.no_grad():\n",
        "  model = GoogLeNet(n_classes=n_classes, use_aux_logits=True)\n",
        "  s = timer()\n",
        "  result = model(torch.tensor(x))\n",
        "  t = timer()-s\n",
        "\n",
        "# Veamos si todo fue OK :)\n",
        "sizes = [result['hidden'].shape[0]] + list(result['logits'].size()) + [d for a in result['aux_logits'] for d in a.size()]\n",
        "corrector.submit(homework=4, question=\"1b\", test=1, token=token, answer=sizes, time=t)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cached test data\n",
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwTQpC0eCKp3"
      },
      "source": [
        "## 1c) Arquitectura Convolucional: _____\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMLkLKGFoTKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "0610ed32-a579-470d-e1ec-73ac7fce66a8"
      },
      "source": [
        "# Acá el código para tu primera arquitectura\n",
        "\n",
        "class ...(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(..., self).__init__()\n",
        "\n",
        "    # Define las capas de convolución y pooling de tu arquitectura\n",
        "    ...\n",
        "\n",
        "    # Capa de salida (antes de la función de salida)\n",
        "    self.fc_out = nn.Linear(..., n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Computa las representaciones internas de la red\n",
        "    ...\n",
        "\n",
        "    # N x out_size\n",
        "    logits = self.fc_out(...)\n",
        "\n",
        "    # En hidden debes devolver alguna de las capas oculta de la red\n",
        "    return {'hidden': ..., 'logits': logits}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-a24c073de58c>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    class ...(nn.Module):\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE6uDwmJ94-W"
      },
      "source": [
        "## 1d) Clasificación de Imágenes en CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1InBxxn28TJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5622f3dd-6260-426a-c993-9e4580678142"
      },
      "source": [
        "##############################################################################\n",
        "# Todo este código sirve para descargar, preprocesar y dejar los datos\n",
        "# listos para usar después. Después de ejecutar las celdas tendrás los datos \n",
        "# trainset, trainloader y similar para test.\n",
        "##############################################################################\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecHwyZa6oxMc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "49f88e0b-ec5a-470d-ddb4-bc428eff84b3"
      },
      "source": [
        "# Definamos algunos hiper-parámetros\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.001\n",
        "EPOCHS = 5\n",
        "REPORTS_EVERY = 1\n",
        "\n",
        "net =  GoogLeNet(n_classes=10, use_aux_logits=True)# tu modelo de CNN (para clasificar en 10 clases)\n",
        "optimizer = optim.Adam(net.parameters(), lr=LR) # optimizador, e.g., optim.SGD, optim.Adam, ...\n",
        "criterion = nn.CrossEntropyLoss() # función de pérdida\n",
        "scheduler = None # (opcional) optim.lr_scheduler proporciona varios métodos para ajustar el lr según el número de épocas\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=4*BATCH_SIZE,\n",
        "                         shuffle=False, num_workers=2)\n",
        "\n",
        "# ipdb.set_trace()\n",
        "# train_loss, acc = train_for_classification(net, train_loader, test_loader, optimizer, criterion)\n",
        "train_loss, acc = train_for_classification(net, train_loader, test_loader, optimizer, criterion, epochs=EPOCHS, reports_every=REPORTS_EVERY)\n",
        "\n",
        "plot_results(train_loss, acc)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1(50000/50000), Loss:1.93504, Train Acc:20.1%, Validating..., Val Acc:20.40%, Avg-Time:55.256s.\n",
            "Epoch:2(50000/50000), Loss:1.60789, Train Acc:34.4%, Validating..., Val Acc:45.16%, Avg-Time:55.776s.\n",
            "Epoch:3(50000/50000), Loss:1.31414, Train Acc:51.9%, Validating..., Val Acc:54.86%, Avg-Time:55.826s.\n",
            "Epoch:4(50000/50000), Loss:1.15762, Train Acc:58.7%, Validating..., Val Acc:59.47%, Avg-Time:55.502s.\n",
            "Epoch:5(50000/50000), Loss:1.04957, Train Acc:63.0%, Validating..., Val Acc:62.24%, Avg-Time:55.657s.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoEdEQnedJMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f20b5d0-9d20-40fa-de89-a727611f2cbe"
      },
      "source": [
        "# Test\n",
        "x, y = list(test_loader)[0]\n",
        "net.cpu()\n",
        "net.eval()\n",
        "y_pred = net(x)['logits'].max(dim=1)[1]\n",
        "\n",
        "# Veamos como se comporta el modelo\n",
        "print(\"Correct Test!\" if (y==y_pred).sum()/len(x) >= .75 else \"Failed Test! [acc]\")"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed Test! [acc]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmALm7EtpFow"
      },
      "source": [
        "## 1e) Opcional: CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prIQA-PjpqV7"
      },
      "source": [
        "##############################################################################\n",
        "# Toda esta parte es similar a la anterior pero para CIFAR100.\n",
        "##############################################################################\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data/cifar100', train=True,\n",
        "                                         download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data/cifar100', train=False,\n",
        "                                        download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDSB4v2x8T3k"
      },
      "source": [
        "# Definamos algunos hiper-parámetros\n",
        "BATCH_SIZE = ...\n",
        "LR = ...\n",
        "EPOCHS = ...\n",
        "REPORTS_EVERY = 1\n",
        "\n",
        "net = ... # tu modelo de CNN (para clasificar en 100 clases)\n",
        "optimizer = ... # optimizador, e.g., optim.SGD, optim.Adam, ...\n",
        "criterion = nn.CrossEntropyLoss() # función de pérdida\n",
        "scheduler = ... # (opcional) optim.lr_scheduler proporciona varios métodos para ajustar el lr según el número de épocas\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=4*BATCH_SIZE,\n",
        "                         shuffle=False, num_workers=2)\n",
        "\n",
        "train_loss, acc = train_for_classification(net, train_loader, \n",
        "                                           test_loader, optimizer, \n",
        "                                           criterion, lr_scheduler=scheduler, \n",
        "                                           epochs=EPOCHS, reports_every=REPORTS_EVERY)\n",
        "\n",
        "plot_results(train_loss, acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRNeU6di3NzC"
      },
      "source": [
        "# Parte 2: Subtitulado de Imágenes mediante Recuperación de Textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twAZ0BtioCT0"
      },
      "source": [
        "## 2a) Codificación de Imágenes y Textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9zd0b1MyAG8"
      },
      "source": [
        "class ImageEncoding(nn.Module):\n",
        "  def __init__(self, cnn_model, cnn_out_size, out_size=128):\n",
        "    super(ImageEncoding, self).__init__()\n",
        "    self.cnn_model = cnn_model\n",
        "\n",
        "    # Defina las capas de su MLP\n",
        "    # Hints: no usar más de 3 capas\n",
        "    #        incorpora alguna técnica de regularización que ya conoces\n",
        "    ...\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cnn_model(x)['hidden']\n",
        "\n",
        "    # Compute las capas de su MLP\n",
        "    ...\n",
        "\n",
        "    # En fc_out debe almacenar el encoding en R^d\n",
        "    return {'logits': ...}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ7NXhVY0xFr"
      },
      "source": [
        "class TextEncoding(nn.Module):\n",
        "  def __init__(self, text_embedding_size=4096, out_size=128):\n",
        "    super(TextEncoding, self).__init__()\n",
        "\n",
        "    # Defina las capas de su MLP\n",
        "    # Hints: no usar más de 3 capas\n",
        "    #        incorpora alguna técnica de regularización que ya conoces\n",
        "    ...\n",
        "\n",
        "    self.use_last_bn = use_last_bn\n",
        "    if use_last_bn:\n",
        "      self.bn = nn.BatchNorm1d(out_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Compute las capas de su MLP\n",
        "    ...\n",
        "\n",
        "    # En logits debe almacenar el encoding en R^d\n",
        "    return {'logits': ...}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08sa7MG4c-GD"
      },
      "source": [
        "# Test\n",
        "OUT_SIZE = 200\n",
        "\n",
        "cnn_net = GoogLeNet()\n",
        "i_enc = ImageEncoding(cnn_model=cnn_net, cnn_out_size=1024, out_size=OUT_SIZE)\n",
        "t_enc = TextEncoding(text_embedding_size=4096, out_size=OUT_SIZE)\n",
        "i_enc.eval()\n",
        "t_enc.eval()\n",
        "\n",
        "# Veamos como se comportan tus encoders\n",
        "print(\"Correct Test!\" if (i_enc(torch.randn(9,3,32,32))['logits'].size()==t_enc(torch.randn(9,4096))['logits'].size()) else \"Failed Test [size]\")\n",
        "print(\"Correct Test!\" if (i_enc(torch.randn(9,3,32,32))['logits'].size(-1)==OUT_SIZE) else \"Failed Test [size]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR8AqpDi3ZJL"
      },
      "source": [
        "## 2b) Buenas codificaciones y la *Triplet Loss*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv0oqLTwv68U"
      },
      "source": [
        "class TripletLoss(nn.Module):\n",
        "  def __init__(self, margin=.2, negative='max'):\n",
        "    super(TripletLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "    self.negative = negative\n",
        "\n",
        "  def forward(self, anchor, positive):\n",
        "    # Posiblemente lo más simple es partir calculando la distancia Euclideana\n",
        "    # entre las imagenes ancla y todos los pares (B x B) de representaciones\n",
        "    # de textos (hint: usa torch.cdist)\n",
        "    dists = ...\n",
        "\n",
        "    # Obtener distancias \"positivas\" de la diagonal\n",
        "    p_dists = ...\n",
        "\n",
        "    # Ahora genera un tensor con todos los costos que se deben agregar\n",
        "    # dependiendo de la forma de encontrar los negativos\n",
        "    if self.negative == 'max':\n",
        "      cost = ...\n",
        "    elif self.negative == 'random':\n",
        "      cost = ...\n",
        "    elif self.negative == 'all':\n",
        "      cost = ...\n",
        "    else:\n",
        "      raise ValueError()\n",
        "    \n",
        "    # Retorna el promedio de los costos de todos los triples considerados\n",
        "    return ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKUFhf70nbd"
      },
      "source": [
        "# Tests del API del curso para TripletLoss\n",
        "\n",
        "# Obtengamos algunos parametros para probar tu implementación\n",
        "for test in [1,2]:\n",
        "  a, p, m, n  = corrector.get_test_data(homework=4, question=\"2b\", test=test, token=token)\n",
        "\n",
        "  criterion = TripletLoss(margin=m, negative=n)\n",
        "  result = criterion(torch.tensor(a), torch.tensor(p)).item()\n",
        "\n",
        "  # Veamos si todo fue OK :)\n",
        "  corrector.submit(homework=4, question=\"2b\", test=test, token=token, answer=result, time=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZcwMyTAwz28"
      },
      "source": [
        "## 2c) Probando tu implementación en Flickr8k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E06OpFAxfuU"
      },
      "source": [
        "##############################################################################\n",
        "# Todo este código sirve para descargar, preprocesar y dejar los datos\n",
        "# listos para usar después. Después de ejecutar las dos celdas siguientes\n",
        "# tendrás los datos en train_flickr_tripletset y similar para val y test\n",
        "##############################################################################\n",
        "\n",
        "folder_path = './data/flickr8k'\n",
        "if not os.path.exists(f'{folder_path}/images'):\n",
        "  print('\\n*** Descargando y extrayendo Flickr8k, siéntese y relájese 4 mins...')\n",
        "  print('****** Descargando las imágenes...\\n')\n",
        "  !wget https://s06.imfd.cl/04/CC6204/tareas/tarea4/Flickr8k_Dataset.zip -P $folder_path/images\n",
        "  print('\\n********* Extrayendo las imágenes...\\n  Si te sale mensaje de colab, dale Ignorar\\n')\n",
        "  !unzip -q $folder_path/images/Flickr8k_Dataset.zip -d $folder_path/images\n",
        "  print('\\n*** Descargando y anotaciones de la imágenes...\\n')\n",
        "  !wget http://hockenmaier.cs.illinois.edu/8k-pictures.html -P $folder_path/annotations\n",
        "\n",
        "transform=transforms.Compose([transforms.ToTensor(), \n",
        "                              transforms.Resize((32, 32)),\n",
        "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "print('Inicializando pytorch Flickr8k dataset')\n",
        "full_flickr_set = torchvision.datasets.Flickr8k(root=f'{folder_path}/images/Flicker8k_Dataset',\n",
        "                                                ann_file = f'{folder_path}/annotations/8k-pictures.html',\n",
        "                                                transform=transform)\n",
        "print('Creando train, val y test splits...')\n",
        "\n",
        "train_flickr_set, val_flickr_set, test_flickr_set = [], [], []\n",
        "for i, item in enumerate(full_flickr_set):\n",
        "  if i<6000:\n",
        "    train_flickr_set.append(item)\n",
        "  elif i<7000:\n",
        "    val_flickr_set.append(item)\n",
        "  else:\n",
        "    test_flickr_set.append(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTY5bha_xgCj"
      },
      "source": [
        "##############################################################################\n",
        "# Descarguemos representaciones de los textos de 4096 dimensiones\n",
        "##############################################################################\n",
        "if not os.path.exists(f'{folder_path}/flickr_cap_encodings_4096d.pkl'):\n",
        "  !wget https://s06.imfd.cl/04/CC6204/tareas/tarea4/flickr_cap_encodings_4096d.pkl -P $folder_path\n",
        "\n",
        "with open(f'{folder_path}/flickr_cap_encodings_4096d.pkl', 'rb') as f:\n",
        "  train_cap_encs, val_cap_encs, test_cap_encs = pickle.load(f)\n",
        "\n",
        "# Creamos un dataset para cada uno de los splits con nuestro ImageCaptionDataset\n",
        "train_flickr_tripletset = ImageCaptionDataset(train_flickr_set, train_cap_encs)\n",
        "val_flickr_tripletset = ImageCaptionDataset(val_flickr_set, val_cap_encs)\n",
        "test_flickr_tripletset = ImageCaptionDataset(test_flickr_set, test_cap_encs)\n",
        "\n",
        "##############################################################################\n",
        "# Acá termina el código para preparar los datos\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THIoPtv-w2QY"
      },
      "source": [
        "##############################################################################\n",
        "# Esta es la parte donde tienes que modificar para poder probar tu \n",
        "# implementación. \n",
        "# En general sólo es necesario que modifiques los lugares con \"...\", pero \n",
        "# eres libre de hacer tus propias implementaciones de todo lo que aparece.\n",
        "##############################################################################\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-4\n",
        "EPOCHS = ...\n",
        "REPORTS_EVERY = 1\n",
        "CNN_OUT_SIZE = ...\n",
        "EMBEDDING_SIZE = 4096\n",
        "OUT_SIZE = 512\n",
        "MARGIN = .2\n",
        "NEGATIVE = ...\n",
        "\n",
        "cnn_net = ...\n",
        "img_net = ImageEncoding(cnn_model=cnn_net, cnn_out_size=CNN_OUT_SIZE, \n",
        "                        out_size=OUT_SIZE) \n",
        "\n",
        "text_net = TextEncoding(text_embedding_size=EMBEDDING_SIZE, out_size=OUT_SIZE)\n",
        "\n",
        "optimizer = optim.Adam([{'params': ...},  # lista de parametros de img_net\n",
        "                        {'params': ...}],  # lista de parametros de text_net\n",
        "                       lr=LR)\n",
        "criterion = TripletLoss(margin=MARGIN, negative=NEGATIVE)\n",
        "scheduler = ... # (opcional) optim.lr_scheduler proporciona varios métodos \n",
        "                # para ajustar el lr según el número de épocas\n",
        "\n",
        "train_triplets_loader = DataLoader(train_flickr_tripletset, batch_size=BATCH_SIZE,\n",
        "                                   shuffle=True, num_workers=2)\n",
        "val_triplets_loader = DataLoader(val_flickr_tripletset, batch_size=BATCH_SIZE,\n",
        "                                 shuffle=False, num_workers=2)\n",
        "\n",
        "train_loss, meanrr, r10 = train_for_retrieval(img_net, text_net, \n",
        "                                              train_triplets_loader, \n",
        "                                              val_triplets_loader, optimizer, \n",
        "                                              criterion, scheduler, EPOCHS, \n",
        "                                              REPORTS_EVERY, norm=False)\n",
        "\n",
        "plot_results(train_loss, meanrr, 'MRR', r10, 'R@10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CYP1n6c6_c8"
      },
      "source": [
        "# Test\n",
        "from PIL import Image\n",
        "n_samples = 64\n",
        "\n",
        "# Tomemos n_samples ejemplos del conjunto de test\n",
        "samples = torch.stack([test_flickr_tripletset[i][0] for i in range(n_samples)]).cuda()\n",
        "refs = torch.stack([torch.from_numpy(test_flickr_tripletset[i][1]) for i in range(n_samples)]).cuda()\n",
        "test_caps = [caps[0] for _, caps in test_flickr_set][:n_samples]\n",
        "\n",
        "# Computamos las representaciones en el espacio compartido\n",
        "samples_enc = img_net(samples)['logits']\n",
        "refs_enc = text_net(refs)['logits']\n",
        "\n",
        "# Calculemos las distancias a cada uno de los textos de test y rankeamos\n",
        "dists = torch.cdist(samples_enc.unsqueeze(0), refs_enc.unsqueeze(0), p=2).squeeze(0)\n",
        "ranks = torch.argsort(dists, dim=1)[:,:10]\n",
        "r10 = len([i for i in range(len(ranks)) if len(torch.where(ranks[i,:] == i)[0])]) / len(ranks)\n",
        "\n",
        "# Veamos como se comporta el modelo\n",
        "print(\"Correct Test!\" if r10 >= .25 else \"Failed Test! [R@10]\")\n",
        "\n",
        "# Mostremos las 10 descripciones más cercanas\n",
        "fig, axs = plt.subplots(nrows=n_samples, figsize=(2,n_samples*5))\n",
        "for i in range(n_samples):\n",
        "  axs[i].imshow(Image.open(full_flickr_set.ids[7000+i]))\n",
        "  axs[i].text(600,0,\"EXPECTED:\\n{}: {}\".format(i, test_caps[i]), fontsize=12, fontweight='bold')\n",
        "  axs[i].text(600,750,\"PREDICTED RANK:\\n{}\".format('\\n'.join([f'{j}: {test_caps[j]}' for j in ranks[i]])), fontsize=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTd9gUB5xwta"
      },
      "source": [
        "## 2d) Opcional: COCO Captions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf0hHCkKx0Kz"
      },
      "source": [
        "##############################################################################\n",
        "# Toda esta parte es similar a la anterior pero para COCO Captions.\n",
        "##############################################################################\n",
        "\n",
        "folder_path = './data/coco-caps'\n",
        "if not os.path.exists(f'{folder_path}/images/train2014'):\n",
        "  print('\\n*** Descargando y extrayendo COCO Captions, siéntese y relájese unos 20 mins...')\n",
        "  print('****** Descargando training set...\\n')\n",
        "  !wget http://images.cocodataset.org/zips/train2014.zip -P $folder_path/images\n",
        "  print('\\n********* Extrayendo training set...\\n  Si te sale mensaje de colab, dale Ignorar\\n')\n",
        "  !unzip -q $folder_path/images/train2014.zip -d $folder_path/images && rm $folder_path/images/train2014.zip\n",
        "  print('\\n*** Descargando y extrayendo validation set...\\n')\n",
        "  !wget http://images.cocodataset.org/zips/val2014.zip -P $folder_path/images && unzip -q $folder_path/images/val2014.zip -d $folder_path/images && rm $folder_path/images/val2014.zip\n",
        "  # !wget http://images.cocodataset.org/zips/test2014.zip -P $folder_path/images && unzip -q $folder_path/images/test2014.zip -d $folder_path/images && rm $folder_path/images/test2014.zip\n",
        "  print('\\n*** Descargando y anotaciones de la imágenes...\\n')\n",
        "  !wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip -P $folder_path && unzip -q $folder_path/annotations_trainval2014.zip -d $folder_path && rm $folder_path/images/annotations_trainval2014.zip\n",
        "\n",
        "transform=transforms.Compose([transforms.ToTensor(), \n",
        "                              transforms.Resize((32, 32)),\n",
        "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_coco_set = torchvision.datasets.CocoCaptions(root=f'{folder_path}/images/train2014',\n",
        "                                                   annFile = f'{folder_path}/annotations/captions_train2014.json',\n",
        "                                                   transform=transform)\n",
        "\n",
        "val_coco_set = torchvision.datasets.CocoCaptions(root=f'{folder_path}/images/val2014',\n",
        "                                                 annFile = f'{folder_path}/annotations/captions_val2014.json',\n",
        "                                                 transform=transform)\n",
        "\n",
        "# test_coco_set = torchvision.datasets.CocoCaptions(root=f'{folder_path}/images/test2014',\n",
        "#                                                   transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUZmJrvfJOxs"
      },
      "source": [
        "if not os.path.exists(f'{folder_path}/cap_encodings_512d.pkl'):\n",
        "  !wget https://s06.imfd.cl/04/CC6204/tareas/tarea4/cap_encodings_512d.pkl -P $folder_path\n",
        "\n",
        "with open(f'{folder_path}/cap_encodings_512d.pkl', 'rb') as f:\n",
        "  train_cap_encs, val_cap_encs = pickle.load(f)\n",
        "\n",
        "train_coco_tripletset = ImageCaptionDataset(train_coco_set, train_cap_encs)\n",
        "val_coco_tripletset = ImageCaptionDataset(val_coco_set, val_cap_encs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXxbiC0bJY6M"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "LR = 1e-4\n",
        "EPOCHS = 10\n",
        "REPORTS_EVERY = 1\n",
        "CNN_PREV_SIZE = 1024\n",
        "EMBEDDING_SIZE = 512\n",
        "OUT_SIZE = 512\n",
        "MARGIN = .2\n",
        "\n",
        "cnn_net = ...\n",
        "img_net = ImageEncoding(cnn_model=..., cnn_out_size=CNN_PREV_SIZE, \n",
        "                        out_size=OUT_SIZE) \n",
        "\n",
        "text_net = TextEncoding(text_embedding_size=EMBEDDING_SIZE, out_size=OUT_SIZE)\n",
        "\n",
        "optimizer = optim.Adam([{'params': ...},\n",
        "                        {'params': ...}], \n",
        "                       lr=LR)\n",
        "criterion = TripletLoss(margin=...)\n",
        "\n",
        "train_triplets_loader = DataLoader(train_coco_tripletset, batch_size=BATCH_SIZE,\n",
        "                                   shuffle=True, num_workers=2)\n",
        "val_triplets_loader = DataLoader(val_coco_tripletset, batch_size=BATCH_SIZE,\n",
        "                                 shuffle=False, num_workers=2)\n",
        "\n",
        "train_loss, meanrr, r10 = train_for_retrieval(img_net, text_net, \n",
        "                                                     train_triplets_loader, \n",
        "                                                     val_triplets_loader, \n",
        "                                                     optimizer, criterion, \n",
        "                                                     EPOCHS, REPORTS_EVERY, \n",
        "                                                     norm=False)\n",
        "\n",
        "plot_results(train_loss, meanrr, 'MRR', r10, 'R@10')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}