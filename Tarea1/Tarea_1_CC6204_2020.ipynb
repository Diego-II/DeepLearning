{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea_1_CC6204_2020.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zhjpqvcdo5o"
      },
      "source": [
        "# Tarea 1: Activaciones y pasada hacia adelante en una red neuronal <br/> CC6204 Deep Learning, Universidad de Chile \n",
        "\n",
        "**Fecha de entrega: 2 de octubre de 2020**\n",
        "\n",
        "[Hoja de Respuestas (con tests automáticos)](https://drive.google.com/file/d/1Xj_0rvpf3zXV69A9xWlohrL8068IrbqZ/view?usp=sharing)\n",
        "\n",
        "En las primeras tareas del curso **progamarás a mano** varios aspectos de redes neuronales Feed Forward. La idea es familiarizarse con tensores, funciones de activación, derivadas, el algoritmo de backpropagation, algoritmos de optimización, regularización, entrenamiento, y búsqueda de hiperparámetros. No se espera obtener excelentes resultados en problemas de clasificación reales, si no más bien aplicar los conceptos teóricos aprendidos en clases y así entenderlos de manera más precisa.  En esta primera tarea sólo nos preocupará la función `forward` de una red neuronal y usaremos una red pre-entrenada para el conjunto de datos MNIST. \n",
        "\n",
        "Te recomendamos que comiences por familiarizarte un poco con [tensores de pytorch](https://pytorch.org/docs/stable/tensors.html) y sus operaciones, que son el objeto básico que usaremos en esta y las siguientes tareas. El material necesario para resolver esta tarea es el siguiente:\n",
        "* [Video: Perceptrón, funciones de activación, y representación matricial](https://www.youtube.com/watch?v=mDCxK2Pu0mA) \n",
        "* [Video: MLP, redes feed-forward, y función de salida](https://www.youtube.com/watch?v=eV-N1ozcZrk&t=1710) (desde el minuto 28:30)\n",
        "* [Apuntes de Redes Feed Forward](https://github.com/jorgeperezrojas/cc6204-DeepLearning-DCCUChile/raw/master/2019/clases/apuntes/1_FFNN.pdf)\n",
        "\n",
        "IMPORTANTE: A menos que se exprese lo contrario, sólo podrás utilizar las clases y funciones en el módulo [`torch`](https://pytorch.org/docs/stable/torch.html). Hay excepciones explicadas en el enunciado de la tarea más adelante. \n",
        "\n",
        "(por Jorge Pérez, https://github.com/jorgeperezrojas, [@perez](https://twitter.com/perez))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_kVL7undMBx"
      },
      "source": [
        "# Este notebook está pensado para correr en CoLaboratory. \n",
        "# Lo único imprescindible por importar es torch \n",
        "import torch\n",
        "\n",
        "# Posiblemenete quieras instalar e importar ipdb para debuggear.\n",
        "# Si es así, descomenta lo siguiente:\n",
        "# !pip install -q ipdb\n",
        "# import ipdb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xbEy3Php0a2"
      },
      "source": [
        "# Parte 1: Funciones de activación y función de salida\n",
        "\n",
        "En esta parte programarás varias funciones que serán de utilidad cuando construyas tu red neuronal. Una cosa **muy importante en esta y las siguientes partes**: evita los loops (`for`, `while`, etc.) a toda costa! todo lo que se pueda hacer con operaciones de tensores sin iterar será muy eficiente (en CPU y GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3nKwdzpqF2y"
      },
      "source": [
        "## 1a) Funciones de activación\n",
        "\n",
        "En esta parte debes programar las siguientes funciones de activación:\n",
        "\n",
        "*   `relu`, que para cada valor $x$ en un tensor computa el máximo entre $0$ y $x$,  \n",
        "*   `swish`, propuesta en el artículo [Searching for Activation Functions](https://arxiv.org/abs/1710.05941), y\n",
        "*   `celu`, propuesta en el artículo [Continuously Differentiable Exponential Linear Units](https://arxiv.org/abs/1704.07483).\n",
        "\n",
        "En cada caso tu función debe recibir un tensor (de cualquier cantidad de dimensiones) y entregar un tensor con la función aplicada a todos sus elementos. La aplicación de las funciones debe ser *punto a punto*, por lo que el tensor de salida de cada función debe tener las mismas dimensiones que el tensor de entrada. **Importante**:  tanto `swish` como `celu` tienen un parámetro que puede modificarse durante el entrenamiento de una red que utilice estas funciones de activación por lo que para estas funciones además del tensor debes recibir el parámetro correspondiente. \n",
        "\n",
        "Como ejemplo, estas son implementaciones de las funciones `sig` y `tanh`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p80-9lwaUAix"
      },
      "source": [
        "# Sigmoid(T)\n",
        "def sig(T):\n",
        "  return torch.reciprocal(1 + torch.exp(-1 * torch.tensor(T)))\n",
        "\n",
        "# Tanh(T)\n",
        "def tanh(T):\n",
        "  E = torch.exp(T)\n",
        "  e = torch.exp(-1 * T)\n",
        "  return (E - e) * torch.reciprocal(E + e)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VtQWFePbtrF"
      },
      "source": [
        "def relu(T):\n",
        "  zeros = torch.zeros_like(T)\n",
        "  return torch.max(T,zeros)\n",
        "\n",
        "def swish(T, beta):\n",
        "  T = torch.tensor(T)\n",
        "  return T * sig(T*beta)\n",
        "\n",
        "def celu(T, alpha):\n",
        "  import math\n",
        "  # output\n",
        "  output = torch.zeros_like(T)\n",
        "  def celu_i(x):\n",
        "    '''\n",
        "    Aux function\n",
        "    '''\n",
        "    if x >= 0:\n",
        "      return x\n",
        "    else:\n",
        "      return alpha*(math.exp(x/alpha)-1)\n",
        "\n",
        "  return T.apply_(celu_i)\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlcJgEIKSWGw",
        "outputId": "1ab394c8-c1d8-4a39-eb40-327706ecf1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# otras pruebas\n",
        "T = torch.randn(4,4)\n",
        "b = 10\n",
        "print(T)\n",
        "print('='*82)\n",
        "print(T*b)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5979,  0.9574,  1.2297, -0.6452],\n",
            "        [ 0.3226, -0.1856,  1.7454, -0.5897],\n",
            "        [ 0.9421,  1.0988, -0.6336, -1.0253],\n",
            "        [ 1.7929,  1.1740,  0.6516,  1.1544]])\n",
            "==================================================================================\n",
            "tensor([[  5.9793,   9.5737,  12.2969,  -6.4515],\n",
            "        [  3.2263,  -1.8564,  17.4540,  -5.8970],\n",
            "        [  9.4215,  10.9876,  -6.3359, -10.2535],\n",
            "        [ 17.9291,  11.7395,   6.5161,  11.5444]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFOoqDSUGDpR",
        "outputId": "71cf5826-d027-41fc-eacc-574806a7dfa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Prueba de relu\n",
        "T = torch.randn(4, 4)\n",
        "print(T)\n",
        "otro_T = relu(T)\n",
        "print('='*80)\n",
        "print(otro_T)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.1864, -0.8730, -0.7394, -0.2218],\n",
            "        [ 0.4851,  0.7385,  0.2040, -0.0020],\n",
            "        [ 1.0000,  0.6994, -0.6335,  1.8499],\n",
            "        [ 0.3484, -1.2260, -1.0201,  0.7452]])\n",
            "================================================================================\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4851, 0.7385, 0.2040, 0.0000],\n",
            "        [1.0000, 0.6994, 0.0000, 1.8499],\n",
            "        [0.3484, 0.0000, 0.0000, 0.7452]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozquOsbeTzRa",
        "outputId": "c117f07b-3838-46c0-da00-424a475cfee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Prueba de swish\n",
        "T = torch.randn(4, 4)\n",
        "print(T)\n",
        "otro_T = swish(T,10)\n",
        "print('='*80)\n",
        "print(otro_T)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.7718,  0.2166,  0.5100, -0.6773],\n",
            "        [ 1.6121,  0.6071, -1.0323,  0.3042],\n",
            "        [ 0.5896,  1.2055,  0.2265,  0.8766],\n",
            "        [-0.9468,  0.9440,  1.9663, -0.5711]])\n",
            "================================================================================\n",
            "tensor([[-3.5776e-08,  1.9432e-01,  5.0687e-01, -7.7426e-04],\n",
            "        [ 1.6121e+00,  6.0573e-01, -3.3933e-05,  2.9032e-01],\n",
            "        [ 5.8802e-01,  1.2055e+00,  2.0523e-01,  8.7644e-01],\n",
            "        [-7.3158e-05,  9.4389e-01,  1.9663e+00, -1.8837e-03]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAHadibUVoFg",
        "outputId": "5599f071-a2ae-4b5d-f6b7-862b15519cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Prueba de celu\n",
        "T = torch.randn(4, 4)\n",
        "print(T)\n",
        "otro_T = celu(T,10)\n",
        "print('='*80)\n",
        "print(otro_T)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3292, -0.0192, -0.5740,  2.1043],\n",
            "        [ 0.5068,  0.1979, -0.6754, -0.5120],\n",
            "        [-0.0478,  1.9906, -0.6062, -0.7648],\n",
            "        [ 0.0965, -0.3530, -1.2330,  1.4820]])\n",
            "================================================================================\n",
            "tensor([[-0.3239, -0.0192, -0.5578,  2.1043],\n",
            "        [ 0.5068,  0.1979, -0.6531, -0.4991],\n",
            "        [-0.0477,  1.9906, -0.5882, -0.7363],\n",
            "        [ 0.0965, -0.3469, -1.1600,  1.4820]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adagNIVPp0fF"
      },
      "source": [
        "## 1b) Softmax\n",
        "\n",
        "En esta parte debes programar la función `softmax`. Esta es una función tal que para una secuencia de valores $(x_1,\\ldots,x_n)$  el resultado de $\\text{softmax}(x_1,\\ldots,x_n)$ es otra secuencia $(s_1,\\ldots,s_n)$ que cumple con\n",
        "\\begin{equation}\n",
        "s_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n}e^{x_j}}\n",
        "\\end{equation}\n",
        "Para esto primero demuestra que si a cada elemento de $(x_1,\\ldots,x_n)$ se le resta el mismo valor, entonces el resultado de `softmax` no varía. Es decir que $\\text{softmax}(x_1-M,\\ldots,x_n-M)=\\text{softmax}(x_1,\\ldots,x_n)$. Usa este hecho para programar una versión de `softmax` que primero le resta a todos los elementos el máximo valor de la secuencia. Esta nueva versión debiera ser numéricamente más estable.\n",
        "\n",
        "Tu función debe recibir un tensor y el resultado de `softmax` debiera calcularse sobre alguna dimensión del tensor dejando todas las demás dimensiones fijas. Para esto tu función debe también recibir el parámetro `dim` (que indica la dimensión). El resultado de `softmax` se calculará para cada secuencia de valores obtenidos recorriendo la dimensión `dim` fijando las otras dimensiones. Por ejemplo, si `softmax` recibe un tensor de dos dimensiones $T_{ij}$ y se elige la dimensión $1$, entonces se debe computar $\\text{softmax}(T_{i1},\\ldots,T_{in})$ para cada $i$. Note que en este caso se calculó `softmax` sobre la dimensión $1$ (la segunda dimensión) dejando fija la dimensión $0$ (la primera dimensión). Como otro ejemplo, si el input de la función es un tensor de tres dimensiones $T_{ijk}$ y se elige la dimensión $2$ (tercera dimensión), entonces se debe computar $\\text{softmax}(T_{ij1},\\ldots,T_{ijn})$ para cada par $i$, $j$. Por si estás familiarizado con `numpy`, el uso de `dim` en esta parte es muy similar al de `axis` en `numpy`.\n",
        "\n",
        "Nota que el resultado de `softmax` es siempre un tensor de las mismas dimensiones de la entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJjtSKdqIic"
      },
      "source": [
        "(La demostración puedes entregarla en otro archivo o incluirla directamente en una celda de la [hoja de respuestas](https://drive.google.com/file/d/1NANjiWP7fWyRBWOf2Pp2gkpRkXheB54s/view?usp=sharing))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdFglXzdXnau"
      },
      "source": [
        "## Demostracion:\n",
        "Por demostrar: $\\text{softmax}(x_1-M,\\ldots,x_n-M)=\\text{softmax}(x_1,\\ldots,x_n)$ \\\\\n",
        "\\begin{align}\n",
        "s_i &= \\frac{e^{x_i - M}}{\\sum_{j=1}^{n}e^{x_j - M}} \\\\\n",
        "\\\\\n",
        "     & = \\frac{e^{x_i}\\cdot e^{-M}}{\\sum_{j=1}^{n}e^{x_j}\\cdot e^{-M}} \\\\\n",
        "\\\\\n",
        "     & = \\frac{e^{x_i}\\cdot e^{-M}}{e^{-M} \\cdot \\sum_{j=1}^{n}e^{x_j}}\n",
        "\\end{align}\n",
        "\n",
        "Luego, simplificando el termino $e^{-M}$, queda que: \\\\\n",
        "\\begin{equation}\n",
        "s_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n}e^{x_j}}\n",
        "\\end{equation} \\\\\n",
        "De esta forma, se demuestra que $\\text{softmax}(x_1-M,\\ldots,x_n-M)=\\text{softmax}(x_1,\\ldots,x_n)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hVvsHp-dGk4",
        "cellView": "code"
      },
      "source": [
        "# Tu código acá\n",
        "\n",
        "def softmax(T, dim, estable=True):\n",
        "  if estable:\n",
        "    exp_i = torch.exp(T - torch.max(T))\n",
        "    softm = torch.tensor(exp_i/torch.sum(exp_i, dim, keepdim=True))\n",
        "    return softm\n",
        "  else: \n",
        "    exp_i = torch.exp(T)\n",
        "    softm = torch.tensor(exp_i/torch.sum(exp_i, dim, keepdim=True))\n",
        "    return softm"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m3i_1ijPLr_"
      },
      "source": [
        "# Parte 2: Red neuronal y pasada hacia adelante (forward)\n",
        "\n",
        "En esta parte empezaremos a programar nuestra red neuronal, en particular la pasada hacia adelante para una red que resolverá problemas de clasificación con varias clases. Supondremos que cada capa se verá de la forma\n",
        "\\begin{equation}\n",
        "h^{(\\ell)} = f^{(\\ell)}(h^{(\\ell-1)} W^{(\\ell)}+b^{(\\ell)})\n",
        "\\end{equation}\n",
        "y que la predicción final estará dada por\n",
        "\\begin{equation}\n",
        "\\hat{y} = \\text{softmax}(h^{(L)}U+c).\n",
        "\\end{equation}\n",
        "\n",
        "(Para entender los detalles de estas fórmulas puedes ver los [apuntes de redes feed forward](https://github.com/jorgeperezrojas/cc6204-DeepLearning-DCCUChile/raw/master/2019/clases/apuntes/1_FFNN.pdf).)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_1cvyD9PiMY"
      },
      "source": [
        "## 2a) Clase para red neuronal\n",
        "\n",
        "Programa una clase `FFNN` que en su inicializador reciba los siguientes parámetros:\n",
        "\n",
        "*   Cantidad de neuronas de la capa de entrada `F`\n",
        "*   Lista de cantidades de neuronas en cada capa escondida `l_h`\n",
        "*   Lista de funciones de activación `l_a`\n",
        "*   Cantidad de neuronas de la capa de salida `C` (`C` $\\geq 2$)\n",
        "\n",
        "En pytorch, todas las redes neuronales que construyamos deben construirse como subclases de [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), lo que tendrá varias ventajas que explicaremos después. El inicio de tu código debe verse más o menos así:\n",
        "\n",
        "```python\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, ...):\n",
        "    super(FFNN, self).__init__()\n",
        "```\n",
        "\n",
        "El inicializador de tu clase debería crear todos los parámetros para la red como tensores (`torch.tensor`) de las dimensiones correspondientes, y almacenar lo necesario para poder computar la pasada hacia adelante (siguiente parte). Para poder aprovechar las funcionalidades de pytorch, debes **registrar** los parámetros como tales y para esto debes usar la clase [`torch.nn.Parameter`](https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter). Por ahora, para nosotros un parámetro de la red definido con `torch.nn.Parameter` no es nada mas que un tensor y en esta tarea lo usaremos como eso, es decir, utilizando solo las funciones básicas de [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html). El siguiente trozo de código crea un tensor de 100 x 100 con solo zeros y lo registra como parámetro en la red.\n",
        "\n",
        "```python\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, ...):\n",
        "    super(FFNN, self).__init__()\n",
        "    T = torch.zeros(100,100)\n",
        "    self.mi_parametro = torch.nn.Parameter(T)\n",
        "```\n",
        "\n",
        "Inicializa todos los parámetros con números aleatorios pequeños y los sesgos como 0. No olvides definir los parámetros como artibutos de la clase para que otros métodos de la clase tengan acceso a ellos también. En tu caso, como tendrás una cantidad variables de parámetros, debes usar una [torch.nn.ParameterList](https://pytorch.org/docs/stable/nn.html#torch.nn.ParameterList) para agregar los parámetros, que estos queden todos registrados y que las otras funciones tengan acceso a ellos.\n",
        "\n",
        "Una llamada de ejemplo para crear un objeto de tu clase es:\n",
        "```python\n",
        "red_neuronal = FFNN(300,[50,30],[relu,sig],10)\n",
        "``` \n",
        "lo que debiera crear todos los parámetros para una red con 300 neuronas en la capa de entrada, luego una capa escondida de 50 neuronas con activación relu, luego una capa con 30 neuronas y activación sigmoid y finalmente una capa de 10 neuronas de salida. <br><br>\n",
        "\n",
        "Puedes agregarle al inicializador de tu clase todos los parámetros opcionales que estimes conveniente, y construir las funciones que te parezcan importantes de construir. Por ejemplo, es recomendable tener alguna forma de asignar los valores iniciales de los parámetros de la red, lo que servirá por ejemplo para cargar redes pre-entrenadas, inicializar los valores de manera más efectiva, o para hacer debugging del código. También puedes pedir los valores iniciales de los parámetros adicionales de las funciones `celu` y `swish`  (no olvides registrarlos como parámetros también!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW3fhiQPTMLT"
      },
      "source": [
        "# Tu código debiera comenzar así (ojo que acá solo empieza el código, \n",
        "# lo iremos completando más adelante).\n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C):\n",
        "    super(FFNN, self).__init__()\n",
        "    # capa de entrada\n",
        "    self.F = torch.nn.Parameter(torch.rand(F))\n",
        "    # capa oculta\n",
        "    self.hidden = torch.nn.ParameterList([torch.nn.parameter(torch.rand(hidden_size)) for hidden_size in l_h])\n",
        "    # funciones de activacion\n",
        "    self.activation = l_a\n",
        "    # capa salida\n",
        "    self.C = torch.nn.Parameter(torch.rand(C))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1TdSMX8XJD5"
      },
      "source": [
        "## 2b) Iterando por los parámetros\n",
        "\n",
        "Uno de los puntos positivos de construir una red en pytorch desde `torch.nn.Module` y registrar los parámetros usando `torch.nn.Parameter` es que puedes tener acceso a un \"iterador\" sobre todos los parámetros llamando a `.parameters()` (esto será muy importante más adelante cuando veamos el algoritmo de backpropagation). Usa este iterador para mostrar/imprimir un resumen de los parámetros de tu red. Debes mostrar al menos las dimensiones de cada uno de los parámetros. Puede serte útil usar el iterador `.named_parameters()` también\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fGGVBrtX2xx"
      },
      "source": [
        "# Tu código debiera continuar así\n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C):\n",
        "    super(FFNN, self).__init__()\n",
        "    # capa de entrada\n",
        "    self.input_layer = torch.nn.Parameter(torch.rand(F))\n",
        "    # capa oculta\n",
        "    self.hidden_layer = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(hidden_size)) for hidden_size in l_h])\n",
        "    # funciones de activacion\n",
        "    self.activation = l_a\n",
        "    # capa salida\n",
        "    self.output_layer = torch.nn.Parameter(torch.rand(C))\n",
        "  \n",
        "  def resumen(self):\n",
        "    # usa self.parameters() o self.named_parameters()\n",
        "    return self.named_parameters()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44m4QzokZtLk",
        "outputId": "e5c941b5-f785-45fb-e16a-7018a0516437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "#instanciemos una red y probemos:\n",
        "red_neuronal = FFNN(300,[50,30],[relu,sig],10)\n",
        "red_neuronal.resumen"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method FFNN.resumen of FFNN(\n",
              "  (hidden_layer): ParameterList(\n",
              "      (0): Parameter containing: [torch.FloatTensor of size 50]\n",
              "      (1): Parameter containing: [torch.FloatTensor of size 30]\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbDabd2LMQCx"
      },
      "source": [
        "## 2c) Moviendo los parámetros de la red entre dispositivos\n",
        "\n",
        "Otro de los puntos positivos de construir una red en pytorch desde `torch.nn.Module` y registrar los parámetros usando `torch.nn.Parameter` es que puedes mover tu red completa entre la CPU y la GPU de manera muy simple. De hecho, como subclase de `torch.nn.Module` podemos usar el método `.to(device)`, de la siguiente forma. Si haces esto:\n",
        "```python\n",
        "red_neuronal = FFNN(300,[50,30],[relu,sig],10)\n",
        "red_neuronal.to('cuda')\n",
        "```\n",
        "tu red pasa automáticamente a la GPU, lo que significa que todos los parámetros de la red quedan efectivamente almacenados en la memoria de la GPU. Para devolver los parámetros a la CPU puedes simplemente hacer\n",
        "```python\n",
        "red_neuronal.to('cpu')\n",
        "```\n",
        "También puedes usar directamente los métodos `.cuda()` y `.cpu()` para lograr los mismo efectos descritos anteriormente.\n",
        "\n",
        "En esta parte no debes programar nada nuevo, solo comprueba que todo anda bien ejecutando las llamadas anteriores y comprobando que efectivamente la memoria de la GPU se utiliza cuando haces la llamada `to.('cuda')`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTgxEjzjMPj6",
        "outputId": "a6e305c1-1b82-4caa-ec32-c92c08497656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "# Crea una red (idealmente grande), y verifica que puedes pasar\n",
        "# todos los parámetros a la GPU ejecutando !nvidia-smi para chequear\n",
        "# la cantidad de GPU-RAM utilizada.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "red_neuronal.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN(\n",
              "  (hidden_layer): ParameterList(\n",
              "      (0): Parameter containing: [torch.cuda.FloatTensor of size 50 (GPU 0)]\n",
              "      (1): Parameter containing: [torch.cuda.FloatTensor of size 30 (GPU 0)]\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUk5lUM8TtBL"
      },
      "source": [
        "## 2d) Pasada hacia adelante\n",
        "\n",
        "Programa la pasada hacia adelante de tu red neuronal en el método `forward` de la clase `FFNN`. La función debiera recibir un tensor de dimensiones `(B,F)` como entrada donde `B` es el tamaño del mini paquete de ejemplos pasados a tu red, y `F` la cantidad de *features* de cada ejemplo. Para computar la pasada hacia adelante, tu red debiera usar los parámetros creados en el inicializador y las funciones de activación entregadas también en el inicializador. Al finalizar, tu red debiera generar predicciones en la forma de probabilidades, aplicando la función `softmax`. El resultado del último `softmax` debiera ser un tensor de dimensiones `(B,C)` que es lo que la función debe retornar (donde `C` representa la cantidad de clases a clasificar)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QseFyNzlUuAx"
      },
      "source": [
        "# Tu código debiera continuar así \n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C):\n",
        "    super(FFNN, self).__init__()\n",
        "    # capa de entrada\n",
        "    # capa oculta\n",
        "    for i, hidden_size in enumerate(l_h):\n",
        "      if i == 0:\n",
        "        self.hidden_layers = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(F, hidden_size))])\n",
        "      else:  \n",
        "        self.hidden_layers.append(torch.nn.Parameter(torch.rand(l_h[i-1], hidden_size)))  \n",
        "    # self.hidden_layers = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(hidden_size)) for hidden_size in l_h])\n",
        "    # baias:\n",
        "    self.baias = torch.nn.ParameterList([torch.nn.Parameter(torch.zeros(hidden_size)) for hidden_size in l_h])\n",
        "    # funciones de activacion\n",
        "    self.activation = l_a\n",
        "    # capa salida\n",
        "    self.output_layer = torch.nn.Parameter(torch.rand(l_h[i],C))\n",
        "    # Baias output layer\n",
        "    self.output_bias = torch.nn.Parameter(torch.zeros(C))\n",
        "  \n",
        "  def resumen(self):\n",
        "    # usa self.parameters() o self.named_parameters()\n",
        "    return self.named_parameters()\n",
        "\n",
        "  def load_parameters(self, W, B, U, C):\n",
        "    for i, layer in enumerate(self.hidden_layers):\n",
        "      layer.data = (W[i])\n",
        "    \n",
        "    for i, baias in enumerate(self.baias):\n",
        "      baias.data = (B[i])\n",
        "    \n",
        "    self.output_bias.data = (C)\n",
        "    self.output_layer.data = (U)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # Usa los parámetros y funciones de activación.\n",
        "    # El valor de retorno debiera ser y = softmax(capa_de_salida).\n",
        "    #h = x.mm(self.input_layer)\n",
        "    h = x\n",
        "    for i, F in enumerate(self.activation):\n",
        "      print(i)\n",
        "      h = F(h @ self.hidden_layers[i] +  self.baias[i])\n",
        "\n",
        "    out = softmax(h @ self.output_layer + self.output_bias, -1 ,  estable = True)\n",
        "    return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqdV6KXRiHNP"
      },
      "source": [
        "red_neuronal = FFNN(25,[50,30],[relu,sig],10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8cDv_OL0gvD",
        "outputId": "b9a35a33-22a3-4e92-a175-b0b655bcd12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "print(red_neuronal)\n",
        "#print(red_neuronal.input_layer.shape)\n",
        "print(red_neuronal.output_layer.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (hidden_layers): ParameterList(\n",
            "      (0): Parameter containing: [torch.FloatTensor of size 25x50]\n",
            "      (1): Parameter containing: [torch.FloatTensor of size 50x30]\n",
            "  )\n",
            "  (baias): ParameterList(\n",
            "      (0): Parameter containing: [torch.FloatTensor of size 50]\n",
            "      (1): Parameter containing: [torch.FloatTensor of size 30]\n",
            "  )\n",
            ")\n",
            "torch.Size([30, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eajQlojSzKj",
        "outputId": "2d3513f8-f692-4395-8499-0d8bc698a270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "red_neuronal(torch.rand(5,25))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3010, 0.2355, 0.0038, 0.0180, 0.0059, 0.0205, 0.1848, 0.0388, 0.0164,\n",
              "         0.1754],\n",
              "        [0.3010, 0.2355, 0.0038, 0.0180, 0.0059, 0.0205, 0.1848, 0.0388, 0.0164,\n",
              "         0.1754],\n",
              "        [0.3010, 0.2355, 0.0038, 0.0180, 0.0059, 0.0205, 0.1848, 0.0388, 0.0164,\n",
              "         0.1754],\n",
              "        [0.3010, 0.2355, 0.0038, 0.0180, 0.0059, 0.0205, 0.1848, 0.0388, 0.0164,\n",
              "         0.1754],\n",
              "        [0.3010, 0.2355, 0.0038, 0.0180, 0.0059, 0.0205, 0.1848, 0.0388, 0.0164,\n",
              "         0.1754]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnyrrdzS4ICK"
      },
      "source": [
        "# Parte 3: Probando tu red con parámetros pre-entrenados para MNIST\n",
        "\n",
        "En esta parte usarás la pasada hacia adelante de tu red con parámetros de una red pre-entrenada. La red fue entrenada con el conjunto de datos MNIST que contiene datos de dígitos escritos a mano. La versión original de los datos junto con una descripción del conjunto y resultados para distintos métodos de clasificación, se pueden encontrar en http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4YdUVgQIUWK"
      },
      "source": [
        "## 3a) Cargando y visualizando datos de MNIST\n",
        "\n",
        "Esta parte no requiere que escribas código, sólo que te familiarices con el conjunto de datos. Sólo sigue las instrucciones.\n",
        "Primero usaremos el paquete `torchvision` (más algunos otros utilitarios) para descargar y procesar los datos de MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE1iMUNfIT1r",
        "outputId": "9bebb443-f917-4deb-edad-3b3b6637e2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Importamos MNIST desde torchvision.\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "# Importamos una función para convertir imágenes en tensores.\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Importamos funcionalidades útiles para mirar los datos.\n",
        "from matplotlib.pyplot import subplots\n",
        "from random import randint\n",
        "\n",
        "# Descarga y almacena el conjunto de prueba de MNIST.\n",
        "dataset = datasets.MNIST(root='./data',\n",
        "                             train=False,\n",
        "                             download=True,\n",
        "                             transform=ToTensor())\n",
        "#dataset = MNIST('mnist', train=False, transform=ToTensor())\n",
        "print('Cantidad total de datos:',len(dataset))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad total de datos: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYGe_7Hp5Vy_"
      },
      "source": [
        "Los datos en todo dataset de pytorch se pueden acceder indexándolos como si fueran un arreglo. En el caso de MNIST cada dato es un par que contiene un tensor `T` y un entero `l`, en donde `T` representa a la imágen de un dígito, y `l` representa el valor numérico de ese dígito. Exploremos el primero de estos datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpmhWb6L5xS8",
        "outputId": "221ef169-4af1-434f-b819-6978ad19d619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "T, l = dataset[0]\n",
        "\n",
        "print('Tensor')\n",
        "print('tipo:', T.type())\n",
        "print('dimensiones:', T.size())\n",
        "print()\n",
        "print('Entero')\n",
        "print('valor:', l)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor\n",
            "tipo: torch.FloatTensor\n",
            "dimensiones: torch.Size([1, 28, 28])\n",
            "\n",
            "Entero\n",
            "valor: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR309L2Q6zrT"
      },
      "source": [
        "El tensor `T` representa una imagen de 28x28 pixeles. Nota que el dato en cuestión tiene una dimensión inicial (es un tensor de 1x28x28). Esto es porque la imagen que estamos considerando está en blanco y negro, por lo tanto tiene un solo canal de color (más adelante usaremos imágenes generales con tres canales y que por lo tanto serán representadas con tensores de dimensiones 3xHxW).\n",
        "\n",
        "El siguiente código muestra el contenido de estos tensores de manera más amigable. Elige tres posiciones al azar y  muestra el valor `l` y el tensor `T` dibujado. Nota como se usa `view(28,28)` para redimensionar el tensor (sacarle la primera dimensión). En este caso también se usa `.numpy()` para pasar el tensor a un formato más amigable para graficar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-7phemizyd6",
        "outputId": "b7112547-27d4-4843-8242-61b5689a5683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "import random\n",
        "# Muestra algunos ejemplos al azar\n",
        "n_ejemplos = 3\n",
        "fig, axs = subplots(nrows=n_ejemplos, figsize=(2,n_ejemplos*3))\n",
        "\n",
        "for i in range(n_ejemplos):  \n",
        "  idx = random.randint(0,len(dataset))\n",
        "  T, l = dataset[idx]\n",
        "  img = T.view(28,28).numpy()\n",
        "  axs[i].set_title(\"clase: \"+ str(l))\n",
        "  axs[i].imshow(img)\n",
        "\n",
        "# Note que se usó `view` para redimensionar el tensor, esto porque nuestro\n",
        "# dataloader entrega un tensor de dimensiones (1,1,28,28).\n",
        "# Es muy importante tener este hecho en cuenta en la siguiente parte."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x648 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44A1SkL9uaE"
      },
      "source": [
        "## 3b) Cargando los parámetros pre-entrenados\n",
        "\n",
        "En [este link](https://github.com/jorgeperezrojas/cc6204-DeepLearning-DCCUChile/tree/master/2019/tareas/tarea1/mnist_weights) encontrarás varios archivos de texto que representan los parámetros de una red con 2 capas escondidas que fue pre-entrenada para clasificar los datos de MNIST. La red pre-entrenada tiene esta arquitectura\n",
        "\n",
        "784 --> 32 (relu) --> 16 (relu) --> 10 (softmax)\n",
        "\n",
        "Nota que la cantidad de neuronas en la capa de entrada es 28*28 = 784, esto porque nuestras redes esperan un vector de características como input.\n",
        "\n",
        "Los archivos de parámetros están nombrados como `W1`, `b1`, `W2`, `b2`, `U` y `c` que representan, respectivamente, a $W^{(1)}$, $b^{(1)}$, $W^{(2)}$, $b^{(2)}$, $U$ y $c$ en la descripción genérica que hemos utilizado para nuestras redes neuronales.\n",
        "\n",
        "Supongamos que ya tenemos guardado el archivo `W1.txt`. Para convertir estos archivos en tensores de pytorch, puedes hacer algo como lo siguiente:\n",
        "\n",
        "```python\n",
        "from numpy import loadtxt\n",
        "W1 = torch.from_numpy(loadtxt('W1.txt')).float()\n",
        "```\n",
        "\n",
        "Usa lo anterior para crear una red con la arquitectura descrita y cargar todos los parámetros pre-entrenados en la red. Esto debes hacerlo llamando a un método de inicialización de pesos de tu red. Si no hiciste ese método en las partes anteriores, es el momento de implementarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx_F1Vs09vFS"
      },
      "source": [
        "# Tu código acá\n",
        "# U.txt\n",
        "!wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/U.txt\n",
        "# W1.txt\n",
        "!wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/W1.txt\n",
        "# W2.txt\n",
        "!wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/W2.txt\n",
        "# b1.txt\n",
        "!wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/b1.txt\n",
        "# b2.txt\n",
        "!wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/b2.txt\n",
        "# c.txt\n",
        "!wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/c.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCdpCNr-pr8Z"
      },
      "source": [
        "from numpy import loadtxt\n",
        "W1 = torch.from_numpy(loadtxt('W1.txt')).float()\n",
        "W2 = torch.from_numpy(loadtxt('W2.txt')).float()\n",
        "U = torch.from_numpy(loadtxt('U.txt')).float()\n",
        "b1 = torch.from_numpy(loadtxt('b1.txt')).float()\n",
        "b2 = torch.from_numpy(loadtxt('b2.txt')).float()\n",
        "C = torch.from_numpy(loadtxt('c.txt')).float()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw37LcgRrMD0",
        "outputId": "dbf676cd-d93d-452a-80c2-64a600f00f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "modelo = FFNN(784,[32,16],[relu,relu],10)\n",
        "print(modelo)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (hidden_layers): ParameterList(\n",
            "      (0): Parameter containing: [torch.FloatTensor of size 784x32]\n",
            "      (1): Parameter containing: [torch.FloatTensor of size 32x16]\n",
            "  )\n",
            "  (baias): ParameterList(\n",
            "      (0): Parameter containing: [torch.FloatTensor of size 32]\n",
            "      (1): Parameter containing: [torch.FloatTensor of size 16]\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQWn9w6BsD6h"
      },
      "source": [
        "for param in modelo.parameters():\n",
        "  param.requires_grad = False\n",
        "modelo.load_parameters([W1,W2],[b1,b2], U, C)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ZacPSF1T2L",
        "outputId": "8de7735b-6e7c-4920-88a3-d87c44a669f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "print(modelo.output_bias)\n",
        "print(C)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([-0.1841,  0.1299,  0.0363, -0.1974,  0.0875,  0.1237, -0.2129, -0.1553,\n",
            "        -0.0097,  0.1864])\n",
            "tensor([-0.1841,  0.1299,  0.0363, -0.1974,  0.0875,  0.1237, -0.2129, -0.1553,\n",
            "        -0.0097,  0.1864])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHJ1TkNhBIjK"
      },
      "source": [
        "## 3c) Cálcula la predicción de un ejemplo al azar\n",
        "\n",
        "Prueba con un código tan simple como puedas, la predicción que entrega tu red para un ejemplo al azar del conjunto de datos y muestra también la imágen y la clase real del ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xWZ19i0BH0a",
        "outputId": "641f9dd0-acfe-4703-d9f5-bf297d3b02b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Tu código aca\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "cpu = 'cpu'\n",
        "modelo.to(cpu)\n",
        "idx = random.randint(0,len(dataset))\n",
        "T, l = dataset[idx]\n",
        "img = T.view(28,28).numpy()\n",
        "print(modelo.forward(T.reshape(784)))\n",
        "print(\"l = \", l)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "tensor([9.9811e-01, 5.7510e-13, 2.5111e-06, 3.1465e-06, 2.7972e-07, 1.1341e-04,\n",
            "        1.4122e-03, 7.5662e-07, 3.5664e-04, 4.2285e-06])\n",
            "l =  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0811568320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m_vQqoXUH2T"
      },
      "source": [
        "def accuracy(y_hat_b, yb):\n",
        "    \n",
        "    preds = torch.argmax(y_hat_b,dim=1)\n",
        "\n",
        "    counts = (preds == yb)*1.0\n",
        "    \n",
        "    return torch.mean(counts)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGiVllhvXaRB",
        "outputId": "d17f2f20-c50f-4506-a429-2b8d74df2b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sRsJcSW_sZ6"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=100)\n",
        "modelo.to(device)\n",
        "acc = []\n",
        "for i, (x, y) in enumerate(dataloader):\n",
        "  y_hat = modelo(x.view(-1,784).to(device))\n",
        "  acc.append(accuracy(y_hat.to(cpu), y.to(cpu)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTU4ONqhZbrq",
        "outputId": "6f4aa5e5-e99a-40aa-cf16-9d9f11bb1f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"accuracy total: \", sum(acc)/len(acc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy total:  tensor(0.9612)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R_2hUZjByHI"
      },
      "source": [
        "## 3d) Pasando todos los ejemplos por la red con un `DataLoader`\n",
        "\n",
        "Un `DataLoader` en pytorch es una manera muy útil de entregarle paquetes de ejemplos a una red. Será especialmente útil cuando estemos entrenando. Por ahora lo usaremos sólo para computar la predicción de la red pre-entrenada y calcular el porcentaje de acierto.\n",
        "\n",
        "Para crear un `DataLoader` solo se debe especificar el conjunto de datos que se usará en la forma de un objeto `DataSet`, y el tamaño del paquete de cada paquete que usaremos. En el siguiente código estamos creando un `DataLoader` desde nuestro objeto `dataset` con paquetes de tamaño 100.\n",
        "\n",
        "```python\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=100)\n",
        "```\n",
        "\n",
        "Una vez creado podemos iterar por todo el dataset haciendo simplemente:\n",
        "\n",
        "```python\n",
        "for x, y in dataloader:\n",
        "  # lo que necesitemos hacer con los datos\n",
        "```\n",
        "\n",
        "En cada iteración `x` será un tensor con 100 ejemplos, por lo tanto tendrá dimensiones 100 x 1 x 28 x 28, e `y` será un tensor con las clases correspondientes a cada uno de esos ejemplos, por lo tanto tendrá dimensión 100 (es un tensor con 100 valores enteros).\n",
        "\n",
        "Escribe una función que use un `DataLoader` para pasar todos los ejemplos por la red en paquetes y calcula el porcentaje total de acierto que la red obtiene en la predicción. Recuerda que el porcentaje total de acierto es la cantidad de ejemplos clasificados correctamente dividido por la cantidad de ejemplos. Tu función debe recibir a la red con los parámetros cargados, el dataset que usarás, el tamaño del batch para pasar por la red y si el trabajo debe hacerse en la GPU o en la CPU. Aprovecha de probar como varía el tiempo de ejecución de tu función si cambias el tamaño del paquete y si usas la GPU vs la CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWdYn-UPGMQf"
      },
      "source": [
        "# Acá tu código\n",
        "def calcula_acierto(red, dataset, batch_size=100, device='cuda'):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz-qtzPmHuti"
      },
      "source": [
        "## 3e) Opcional: Muestra los casos en donde la red se equivoca\n",
        "\n",
        "Muestra imágenes de 5 casos en donde la red se equivoca en la predicción (muestra la imagen y el dígito que la red predice). ¿Es razonable el error que comete?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4cVRrRwIGt2"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0P4ECqKAXXp"
      },
      "source": [
        "## 3d) Opcional: Crea tus propios ejemplos de dígitos para clasificar\n",
        "\n",
        "Usa el código en [este link](https://colab.research.google.com/drive/1pdoj2grwFUNa7ZTY5TPefsedY0VDW2_4#scrollTo=8K6u9gS-JXIT) para generar nuevos casos de prueba manualmente y ver cómo lo clasifica la red. Trata de entender en qué casos comete errores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO1p6G6rA96y"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}