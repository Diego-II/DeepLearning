{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Respuestas_Tarea_1_CC6402_2020",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCszeuRk0NuH"
      },
      "source": [
        "# Tarea 1: Activaciones y pasada hacia adelante en una red neuronal <br/> CC6204 Deep Learning, Universidad de Chile  <br/> Hoja de respuestas\n",
        "## Nombre: \n",
        "Fecha de entrega: 2 de octubre de *2020*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QQB7jV7LMEo",
        "outputId": "6727038e-c5c5-4483-907a-8981786a6554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Este notebook está pensado para correr en CoLaboratory. \n",
        "# Lo único imprescindible por importar es torch \n",
        "import torch\n",
        "\n",
        "# Posiblemenete quieras instalar e importar ipdb para debuggear.\n",
        "# Si es así, descomenta lo siguiente\n",
        "# !pip install -q ipdb\n",
        "# import ipdb\n",
        "\n",
        "# Aqui instalamos la libreria de correccion del curso\n",
        "!pip install \"git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cc6204 from git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cc6204) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.6.0+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->cc6204) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49OevYJkMdgW",
        "outputId": "76d2e9dc-441a-48ad-ca1b-d0b625f26f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# importamos las herramientas del curso\n",
        "from cc6204 import AutoCorrect, FailedTest\n",
        "\n",
        "# ingresa el host y port que posteamos en u-cursos\n",
        "\n",
        "corrector = AutoCorrect(host='cc6204.dcc.uchile.cl', port=443)\n",
        "\n",
        "# anota el token que te daremos en u-cursos\n",
        "\n",
        "token = ']ye/Ox;nsz'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connection stablished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq9u0IfT0VRp"
      },
      "source": [
        "# Parte 1: Funciones de activación y función de salida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMw80P8o0qrJ"
      },
      "source": [
        "## 1a) Funciones de activación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDhcNbNT0YNr"
      },
      "source": [
        "# Sigmoid(T)\n",
        "def sig(T):\n",
        "  return torch.reciprocal(1 + torch.exp(-1 * T))\n",
        "\n",
        "# Tanh(T)\n",
        "def tanh(T):\n",
        "  E = torch.exp(T)\n",
        "  e = torch.exp(-1 * T)\n",
        "  return (E - e) * torch.reciprocal(E + e)\n",
        "\n",
        "def relu(T):\n",
        "  T = torch.tensor(T)\n",
        "  zeros = torch.zeros_like(T)\n",
        "  return torch.max(T,zeros)\n",
        "\n",
        "def swish(T, beta):\n",
        "  T = torch.tensor(T)\n",
        "  return T * sig(T*beta)\n",
        "\n",
        "def celu(T, alpha):\n",
        "  T = torch.tensor(T)\n",
        "  import math\n",
        "  def celu_i(x):\n",
        "    '''\n",
        "    Aux function\n",
        "    '''\n",
        "    if x >= 0:\n",
        "      return x\n",
        "    else:\n",
        "      return alpha*(math.exp(x/alpha)-1)\n",
        "\n",
        "  return T.apply_(celu_i)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0SmO2x7M1pn",
        "outputId": "92d8ff68-058a-4dbe-89be-0124bf1ecdfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# correccion\n",
        "test_relu = corrector.get_test_data(homework=1, question=\"1a\", test=1, token=token)\n",
        "test_swish, swish_par = corrector.get_test_data(homework=1, question=\"1a\", test=2, token=token)\n",
        "test_celu, celu_par = corrector.get_test_data(homework=1, question=\"1a\", test=3, token=token)\n",
        "\n",
        "\n",
        "# probablemente quieras convertr los variables test_* a un tensor, ya que por defecto son listas\n",
        "\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=1, token=token, answer=relu(test_relu))\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=2, token=token, answer=swish(test_swish, swish_par))\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=3, token=token, answer=celu(test_celu, celu_par))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct Test!\n",
            "Correct Test!\n",
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_0dTh7l1bas"
      },
      "source": [
        "## 1b) Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjIyp2nL1le5"
      },
      "source": [
        "(La demostración puedes entregarla en otro archivo o incluirla directamente acá)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDg2sU7D1dIY"
      },
      "source": [
        "# Tu código acá\n",
        "\n",
        "def softmax(T, dim, estable=True):\n",
        "  T = torch.tensor(T)\n",
        "  if estable:\n",
        "    exp_i = torch.exp(T - torch.max(T))\n",
        "    softm = torch.tensor(exp_i/torch.sum(exp_i, dim, keepdim=True))\n",
        "    return softm\n",
        "  else: \n",
        "    exp_i = torch.exp(T)\n",
        "    softm = torch.tensor(exp_i/torch.sum(exp_i, dim, keepdim=True))\n",
        "    return softm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nJhjuGZXgkM",
        "outputId": "22540542-133e-4723-e280-6164ab6b2abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "test_softmax, _dim = corrector.get_test_data(homework=1, question=\"1b\", test=1, token=token)\n",
        "corrector.sumbit(homework=1, question=\"1b\", test=1, token=token, answer=softmax(test_softmax, dim=_dim))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "662XLsDA9XXI"
      },
      "source": [
        "# Parte 2: Red neuronal y pasada hacia adelante (forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTUm9ZbX9bRA"
      },
      "source": [
        "## 2a) Clase para red neuronal, 2b) Iterando por parametros, 2d) Pasada hacia adelante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_jeuYbv9WhK"
      },
      "source": [
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C):\n",
        "    super(FFNN, self).__init__()\n",
        "    # capa de entrada\n",
        "    # capa oculta\n",
        "    for i, hidden_size in enumerate(l_h):\n",
        "      if i == 0:\n",
        "        self.hidden_layers = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(F, hidden_size))])\n",
        "      else:  \n",
        "        self.hidden_layers.append(torch.nn.Parameter(torch.rand(l_h[i-1], hidden_size)))  \n",
        "    # self.hidden_layers = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(hidden_size)) for hidden_size in l_h])\n",
        "    # baias:\n",
        "    self.baias = torch.nn.ParameterList([torch.nn.Parameter(torch.zeros(hidden_size)) for hidden_size in l_h])\n",
        "    # funciones de activacion\n",
        "    self.activation = l_a\n",
        "    # capa salida\n",
        "    self.output_layer = torch.nn.Parameter(torch.rand(l_h[i],C))\n",
        "    # Baias output layer\n",
        "    self.output_bias = torch.nn.Parameter(torch.zeros(C))\n",
        "  \n",
        "  def resumen(self):\n",
        "    # usa self.parameters() o self.named_parameters()\n",
        "    return self.named_parameters()\n",
        "\n",
        "  def load_parameters(self, W, B, U, C):\n",
        "    for i, layer in enumerate(self.hidden_layers):\n",
        "      layer.data = (W[i])\n",
        "    \n",
        "    for i, baias in enumerate(self.baias):\n",
        "      baias.data = (B[i])\n",
        "    \n",
        "    self.output_bias.data = (C)\n",
        "    self.output_layer.data = (U)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # Usa los parámetros y funciones de activación.\n",
        "    # El valor de retorno debiera ser y = softmax(capa_de_salida).\n",
        "    h = x\n",
        "    for i, F in enumerate(self.activation):\n",
        "      h = F(h @ self.hidden_layers[i] +  self.baias[i])\n",
        "\n",
        "    out = softmax(h @ self.output_layer + self.output_bias, -1 ,  estable = True)\n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC3poINhhUxU",
        "outputId": "d8cc4c1e-0e88-49ae-abf0-1a0a52e20078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "#instanciemos una red y veamos el resumen:\n",
        "red_neuronal = FFNN(300,[50,30],[relu,sig],10)\n",
        "red_neuronal.resumen"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method FFNN.resumen of FFNN(\n",
              "  (hidden_layers): ParameterList(\n",
              "      (0): Parameter containing: [torch.FloatTensor of size 300x50]\n",
              "      (1): Parameter containing: [torch.FloatTensor of size 50x30]\n",
              "  )\n",
              "  (baias): ParameterList(\n",
              "      (0): Parameter containing: [torch.FloatTensor of size 50]\n",
              "      (1): Parameter containing: [torch.FloatTensor of size 30]\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgf5Xx-34Pa1"
      },
      "source": [
        "## 2c) Moviendo los parámetros entre dispositivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zppplXd4QXa",
        "outputId": "e8b6414a-dcfc-459e-fb41-bd73e50e16cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "# Tu código acá\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "red_neuronal.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN(\n",
              "  (hidden_layers): ParameterList(\n",
              "      (0): Parameter containing: [torch.cuda.FloatTensor of size 300x50 (GPU 0)]\n",
              "      (1): Parameter containing: [torch.cuda.FloatTensor of size 50x30 (GPU 0)]\n",
              "  )\n",
              "  (baias): ParameterList(\n",
              "      (0): Parameter containing: [torch.cuda.FloatTensor of size 50 (GPU 0)]\n",
              "      (1): Parameter containing: [torch.cuda.FloatTensor of size 30 (GPU 0)]\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTnKxznL6Ep"
      },
      "source": [
        "# Parte 3: Probando tu red con parámetros pre-entrenados para MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOBcElJ7BPcQ",
        "outputId": "8388cf12-7d68-4170-97a3-ebc71febd8fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Descarga y almacena el conjunto de prueba de MNIST.\n",
        "dataset = datasets.MNIST(root='./data',\n",
        "                             train=False,\n",
        "                             download=True,\n",
        "                             transform=ToTensor())\n",
        "print('Cantidad total de datos:',len(dataset))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad total de datos: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6s-z1DNL-J0"
      },
      "source": [
        "## 3b) Cargando los parámetros pre-entrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLeq3y8FE3SU",
        "outputId": "61477b98-ca9b-4352-e21e-c3ada2aa8f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import os.path \n",
        "# Descargamos solo una vez los pesos:\n",
        "if os.path.exists('/content/U.txt'):\n",
        "  print('pesos ya descargados')\n",
        "else:\n",
        "  # U.txt\n",
        "  !wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/U.txt\n",
        "  # W1.txt\n",
        "  !wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/W1.txt\n",
        "  # W2.txt\n",
        "  !wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/W2.txt\n",
        "  # b1.txt\n",
        "  !wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/b1.txt\n",
        "  # b2.txt\n",
        "  !wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/b2.txt\n",
        "  # c.txt\n",
        "  !wget https://raw.githubusercontent.com/dccuchile/CC6204/master/versiones_anteriores/2019/tareas/tarea1/mnist_weights/c.txt\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pesos ya descargados\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCdpCNr-pr8Z"
      },
      "source": [
        "from numpy import loadtxt\n",
        "W1 = torch.from_numpy(loadtxt('W1.txt')).float()\n",
        "W2 = torch.from_numpy(loadtxt('W2.txt')).float()\n",
        "U = torch.from_numpy(loadtxt('U.txt')).float()\n",
        "b1 = torch.from_numpy(loadtxt('b1.txt')).float()\n",
        "b2 = torch.from_numpy(loadtxt('b2.txt')).float()\n",
        "C = torch.from_numpy(loadtxt('c.txt')).float()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw37LcgRrMD0",
        "outputId": "93842bd6-701a-42ea-b637-cbfe3bf860cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "modelo = FFNN(784,[32,16],[relu,relu],10)\n",
        "print(modelo)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (hidden_layers): ParameterList(\n",
            "      (0): Parameter containing: [torch.FloatTensor of size 784x32]\n",
            "      (1): Parameter containing: [torch.FloatTensor of size 32x16]\n",
            "  )\n",
            "  (baias): ParameterList(\n",
            "      (0): Parameter containing: [torch.FloatTensor of size 32]\n",
            "      (1): Parameter containing: [torch.FloatTensor of size 16]\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQWn9w6BsD6h"
      },
      "source": [
        "for param in modelo.parameters():\n",
        "  param.requires_grad = False\n",
        "# cargamos los pesos\n",
        "modelo.load_parameters([W1,W2],[b1,b2], U, C)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ZacPSF1T2L",
        "outputId": "bcc26bda-e089-48ba-9e8d-64c8cec5d76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "# Comprobamos que se transfieran los pesos de C:\n",
        "print(modelo.output_bias)\n",
        "print(C)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([-0.1841,  0.1299,  0.0363, -0.1974,  0.0875,  0.1237, -0.2129, -0.1553,\n",
            "        -0.0097,  0.1864])\n",
            "tensor([-0.1841,  0.1299,  0.0363, -0.1974,  0.0875,  0.1237, -0.2129, -0.1553,\n",
            "        -0.0097,  0.1864])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWRa68ZFMIyr"
      },
      "source": [
        "## 3c) Calcula la predicción de un ejemplo al azar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-SaIzRoMMoc",
        "outputId": "bed9a870-1b79-4774-dfb8-bc7a353035f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "# Tu código aca\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "cpu = 'cpu'\n",
        "modelo.to(cpu)\n",
        "idx = random.randint(0,len(dataset))\n",
        "T, l = dataset[idx]\n",
        "img = T.view(28,28).numpy()\n",
        "print(\"Vector output = \", modelo.forward(T.reshape(784)))\n",
        "print(\"Etiqueta imagen = \", l)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector output =  tensor([6.2676e-10, 1.0951e-05, 5.1737e-05, 9.9982e-01, 1.0506e-08, 2.5756e-05,\n",
            "        3.9574e-10, 9.4697e-08, 9.3332e-05, 6.9399e-07])\n",
            "Etiqueta imagen =  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb91e10c908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1cZFU8rMNr1"
      },
      "source": [
        "## 3d) Pasando todos los ejemplos por la red con un `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL49_0ZAMRd_"
      },
      "source": [
        "# Acá tu código\n",
        "from torch.utils.data import DataLoader\n",
        "def accuracy(y_hat_b, yb):    \n",
        "    preds = torch.argmax(y_hat_b,dim=1)\n",
        "    counts = (preds == yb)*1.0    \n",
        "    return torch.mean(counts)\n",
        "\n",
        "def calcula_acierto(red, dataset, batch_size=100, device='cuda:0'):  \n",
        "  dataloader = DataLoader(dataset, batch_size)\n",
        "  red.to(device)\n",
        "  acc = []\n",
        "  for i, (x, y) in enumerate(dataloader):\n",
        "    y_hat = red(x.view(-1,784).to(device))\n",
        "    acc.append(accuracy(y_hat.to(cpu), y.to(cpu)))\n",
        "\n",
        "  return sum(acc)/len(acc)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-VlLKn3egYy",
        "outputId": "2c41fa45-18c2-4b0b-ff8f-861d7d215ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "calcula_acierto(modelo, dataset, 100, device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9612)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKXqo4FpX2Id"
      },
      "source": [
        "### Corrección red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMcid2LRXzrg",
        "outputId": "7388a6c9-42d5-4696-ce34-02b0fcc0213b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Tests del API del curso\n",
        "from torch.utils.data import Subset\n",
        "indices = corrector.get_test_data(homework=1, question=\"network\", test=1, token=token)\n",
        "test_set = Subset(dataset, indices)\n",
        "\n",
        "cpu = 'cpu'\n",
        "# Modelo con los parámetros pre-entrenados para MNIST\n",
        "your_network = modelo.to(cpu)\n",
        "\n",
        "# Montar el `test_set` en un tensor de (N, 28*28) usando DataLoader\n",
        "X = list(DataLoader(test_set, batch_size=len(test_set)))[0][0].view(-1, 28*28)\n",
        "\n",
        "# Almacenar el resultado en un puro tensor de (N,1)\n",
        "result = torch.argmax(your_network(X), dim=1)\n",
        "\n",
        "corrector.sumbit(homework=1, question=\"network\", test=1, token=token, answer=result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pgWygWCMYTx"
      },
      "source": [
        "## 3e) Opcional: Muestra los casos en donde la red se equivoca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM_eP23XMaTn"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beF870pABHKe"
      },
      "source": [
        "## 3d) Opcional: Crea tus propios ejemplos de dígitos para clasificar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOqCJx4LBG1W"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}